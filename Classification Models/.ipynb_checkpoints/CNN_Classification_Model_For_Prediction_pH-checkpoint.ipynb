{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1bc20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b026630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 73, 73, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 73, 73, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 36, 36, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 17, 17, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 87,659,267\n",
      "Trainable params: 87,656,515\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#AlexNet Architecture for P estimation\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(300,300,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de4066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9305407",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lab_tested_data = pd.read_csv('C:\\\\Users\\\\Mahmood Yousaf\\\\Desktop\\\\FYP\\\\Final-Year-Project-Soil-Analysis-using-machine-learning\\\\Lab Results\\\\Soil_Lab_Results - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "843f1705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1572\n"
     ]
    }
   ],
   "source": [
    "print(len(Lab_tested_data))\n",
    "#Getting sample id for each image with its lab value\n",
    "Sample_ID = Lab_tested_data.iloc[:,0]\n",
    "P_Value = Lab_tested_data.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd17e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    Labels = []\n",
    "    image_counter = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        x = filename.split(\"_\")\n",
    "        id = float(x[0])\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        width = 1000\n",
    "        height = 1000\n",
    "        dim = (width, height)\n",
    "        # resize image\n",
    "        img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        img = img[500:800,500:800] #Resizing the image\n",
    "        kernel = np.array([[-1,-1,-1], \n",
    "                   [-1, 9,-1],\n",
    "                   [-1,-1,-1]])\n",
    "        img = cv2.filter2D(img, -1, kernel) # applying the sharpening kernel.\n",
    "        Result = Sample_ID.isin([id])\n",
    "        Result = Sample_ID[Result];\n",
    "        if len(Result) >= 1:\n",
    "            print(image_counter)\n",
    "            image_counter = image_counter + 1\n",
    "            if len(Result) == 2:  \n",
    "                Result = Sample_ID[Sample_ID==Result.iloc[1]].index.tolist()\n",
    "                Id_1_index = Result[0]\n",
    "                Id_2_index = Result[1]\n",
    "                #Average of both inner and surface image soil result \n",
    "                P_lab_value = (P_Value[Id_2_index] + P_Value[Id_2_index]) / 2\n",
    "                #Assigning classs number 0,1,2,3 \n",
    "                if P_lab_value < 3.5:\n",
    "                    Labels.append([filename,img,0])\n",
    "                elif P_lab_value > 3.5 and P_lab_value < 7.0:\n",
    "                    Labels.append([filename,img,1])\n",
    "                elif P_lab_value > 7.0 and P_lab_value < 14.0:\n",
    "                    Labels.append([filename,img,2])\n",
    "                elif P_lab_value > 14.0:\n",
    "                    Labels.append([filename,img,3])\n",
    "            elif len(Result==1):\n",
    "                Result = Sample_ID[Sample_ID==Result.iloc[1]].index.tolist()\n",
    "                Id_1_index = Result[0]\n",
    "                P_lab_value = P_Value[Id_1_index]\n",
    "                #Assigning classs number 0,1,2,3 \n",
    "                if P_lab_value < 3.5:\n",
    "                    Labels.append([filename,img,0])\n",
    "                elif P_lab_value > 3.5 and P_lab_value < 7.0:\n",
    "                    Labels.append([filename,img,1])\n",
    "                elif P_lab_value > 7.0 and P_lab_value < 14.0:\n",
    "                    Labels.append([filename,img,2])\n",
    "                elif P_lab_value > 14.0:\n",
    "                    Labels.append([filename,img,3])\n",
    "        else:\n",
    "            print(len(Result))\n",
    "            print(\"Hi i am here for testing\")\n",
    "            continue\n",
    "    return Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea152f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n"
     ]
    }
   ],
   "source": [
    "#loading dataset \n",
    "dataset = load_images_from_folder('C:\\\\Users\\\\Mahmood Yousaf\\\\Desktop\\\\FYP\\\\Dataset RGB\\\\Training_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240d5e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1052\n"
     ]
    }
   ],
   "source": [
    "#Preparing data for model\n",
    "X = []\n",
    "Y = []\n",
    "for data in dataset:\n",
    "    X.append(data[1])\n",
    "    Y.append(data[2])\n",
    "print(Y)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90d0a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3)\n",
      "[0. 1. 0.]\n",
      "(1052, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "img_size = 300\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3)\n",
    "print(X[0].shape)\n",
    "Y = to_categorical(Y)\n",
    "print(Y[100])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e81e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1052, 300, 300, 3)\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y)\n",
    "print(Y[522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b3a9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmood Yousaf\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1348: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "18/18 [==============================] - ETA: 0s - loss: 40.2569 - accuracy: 0.7808 - precision: 0.0087 - recall: 0.0233 - f1_score: 0.0126          WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "18/18 [==============================] - 15s 326ms/step - loss: 40.2569 - accuracy: 0.7808 - precision: 0.0087 - recall: 0.0233 - f1_score: 0.0126 - val_loss: 314.7524 - val_accuracy: 0.8650 - val_precision: 0.0488 - val_recall: 0.0963 - val_f1_score: 0.0645\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 6.8810 - accuracy: 0.7663 - precision: 0.0418 - recall: 0.1000 - f1_score: 0.0582 - val_loss: 25.6935 - val_accuracy: 0.0422 - val_precision: 0.0421 - val_recall: 0.2386 - val_f1_score: 0.0712\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 5.3638 - accuracy: 0.7609 - precision: 0.0376 - recall: 0.2802 - f1_score: 0.0664 - val_loss: 39.1402 - val_accuracy: 0.0422 - val_precision: 0.0358 - val_recall: 0.3382 - val_f1_score: 0.0647\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 2.8447 - accuracy: 0.7174 - precision: 0.0360 - recall: 0.4177 - f1_score: 0.0662 - val_loss: 37.1018 - val_accuracy: 0.8650 - val_precision: 0.0355 - val_recall: 0.4060 - val_f1_score: 0.0653\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 1.6148 - accuracy: 0.8098 - precision: 0.0356 - recall: 0.3914 - f1_score: 0.0652 - val_loss: 8.4480 - val_accuracy: 0.8650 - val_precision: 0.0384 - val_recall: 0.3882 - val_f1_score: 0.0698\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.8175 - accuracy: 0.7681 - precision: 0.0371 - recall: 0.3624 - f1_score: 0.0673 - val_loss: 9.7837 - val_accuracy: 0.8439 - val_precision: 0.0371 - val_recall: 0.3414 - val_f1_score: 0.0669\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.0377 - accuracy: 0.7989 - precision: 0.0358 - recall: 0.3279 - f1_score: 0.0645 - val_loss: 11.1929 - val_accuracy: 0.6624 - val_precision: 0.0361 - val_recall: 0.3280 - val_f1_score: 0.0650\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.8425 - accuracy: 0.7862 - precision: 0.0360 - recall: 0.3240 - f1_score: 0.0648 - val_loss: 4.0866 - val_accuracy: 0.8650 - val_precision: 0.0364 - val_recall: 0.3111 - val_f1_score: 0.0651\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 2.5847 - accuracy: 0.8062 - precision: 0.0367 - recall: 0.3024 - f1_score: 0.0654 - val_loss: 21.0361 - val_accuracy: 0.8608 - val_precision: 0.0365 - val_recall: 0.3080 - val_f1_score: 0.0653\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 2.7176 - accuracy: 0.8370 - precision: 0.0364 - recall: 0.3108 - f1_score: 0.0652 - val_loss: 50.5494 - val_accuracy: 0.8650 - val_precision: 0.0367 - val_recall: 0.3048 - val_f1_score: 0.0656\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 3.3612 - accuracy: 0.8297 - precision: 0.0365 - recall: 0.3018 - f1_score: 0.0651 - val_loss: 1.3521 - val_accuracy: 0.8439 - val_precision: 0.0365 - val_recall: 0.2951 - val_f1_score: 0.0649\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 1.3390 - accuracy: 0.8279 - precision: 0.0362 - recall: 0.2838 - f1_score: 0.0642 - val_loss: 2.1840 - val_accuracy: 0.3376 - val_precision: 0.0361 - val_recall: 0.2769 - val_f1_score: 0.0639\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.6430 - accuracy: 0.8188 - precision: 0.0358 - recall: 0.2686 - f1_score: 0.0631 - val_loss: 9.3385 - val_accuracy: 0.8397 - val_precision: 0.0359 - val_recall: 0.2779 - val_f1_score: 0.0636\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.7775 - accuracy: 0.8315 - precision: 0.0358 - recall: 0.2818 - f1_score: 0.0635 - val_loss: 22.9256 - val_accuracy: 0.8312 - val_precision: 0.0359 - val_recall: 0.2774 - val_f1_score: 0.0635\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 2.4758 - accuracy: 0.8062 - precision: 0.0364 - recall: 0.2759 - f1_score: 0.0644 - val_loss: 6.5521 - val_accuracy: 0.8650 - val_precision: 0.0371 - val_recall: 0.2826 - val_f1_score: 0.0655\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.3158 - accuracy: 0.8225 - precision: 0.0378 - recall: 0.2875 - f1_score: 0.0668 - val_loss: 17.6944 - val_accuracy: 0.8017 - val_precision: 0.0379 - val_recall: 0.2872 - val_f1_score: 0.0669\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.4710 - accuracy: 0.7736 - precision: 0.0375 - recall: 0.2869 - f1_score: 0.0664 - val_loss: 15.8698 - val_accuracy: 0.8312 - val_precision: 0.0375 - val_recall: 0.2897 - val_f1_score: 0.0663\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.9128 - accuracy: 0.8170 - precision: 0.0375 - recall: 0.2889 - f1_score: 0.0664 - val_loss: 40.2412 - val_accuracy: 0.8143 - val_precision: 0.0382 - val_recall: 0.2931 - val_f1_score: 0.0676\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.7532 - accuracy: 0.7862 - precision: 0.0376 - recall: 0.2898 - f1_score: 0.0665 - val_loss: 21.7831 - val_accuracy: 0.7511 - val_precision: 0.0376 - val_recall: 0.2908 - val_f1_score: 0.0665\n",
      "Epoch 20/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 181ms/step - loss: 1.3255 - accuracy: 0.7736 - precision: 0.0375 - recall: 0.2933 - f1_score: 0.0665 - val_loss: 66.3317 - val_accuracy: 0.6498 - val_precision: 0.0378 - val_recall: 0.2960 - val_f1_score: 0.0670\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.9115 - accuracy: 0.7699 - precision: 0.0373 - recall: 0.2951 - f1_score: 0.0663 - val_loss: 41.0185 - val_accuracy: 0.6540 - val_precision: 0.0376 - val_recall: 0.3008 - val_f1_score: 0.0669\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.5033 - accuracy: 0.7645 - precision: 0.0380 - recall: 0.3059 - f1_score: 0.0676 - val_loss: 27.8286 - val_accuracy: 0.6962 - val_precision: 0.0386 - val_recall: 0.3117 - val_f1_score: 0.0687\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.4216 - accuracy: 0.7880 - precision: 0.0387 - recall: 0.3122 - f1_score: 0.0689 - val_loss: 24.7560 - val_accuracy: 0.7173 - val_precision: 0.0392 - val_recall: 0.3165 - val_f1_score: 0.0698\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.9648 - accuracy: 0.8225 - precision: 0.0393 - recall: 0.3183 - f1_score: 0.0699 - val_loss: 22.2748 - val_accuracy: 0.7046 - val_precision: 0.0399 - val_recall: 0.3231 - val_f1_score: 0.0710\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.8553 - accuracy: 0.7772 - precision: 0.0402 - recall: 0.3260 - f1_score: 0.0716 - val_loss: 12.2812 - val_accuracy: 0.6624 - val_precision: 0.0403 - val_recall: 0.3282 - val_f1_score: 0.0718\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.2835 - accuracy: 0.7989 - precision: 0.0403 - recall: 0.3274 - f1_score: 0.0718 - val_loss: 8.3560 - val_accuracy: 0.8565 - val_precision: 0.0402 - val_recall: 0.3227 - val_f1_score: 0.0715\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.6373 - accuracy: 0.8496 - precision: 0.0407 - recall: 0.3233 - f1_score: 0.0723 - val_loss: 6.6342 - val_accuracy: 0.8312 - val_precision: 0.0409 - val_recall: 0.3204 - val_f1_score: 0.0725\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.2205 - accuracy: 0.8279 - precision: 0.0408 - recall: 0.3156 - f1_score: 0.0723 - val_loss: 14.9042 - val_accuracy: 0.8397 - val_precision: 0.0408 - val_recall: 0.3103 - val_f1_score: 0.0722\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.7027 - accuracy: 0.8333 - precision: 0.0408 - recall: 0.3056 - f1_score: 0.0719 - val_loss: 19.0129 - val_accuracy: 0.8228 - val_precision: 0.0406 - val_recall: 0.3009 - val_f1_score: 0.0716\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 3.4786 - accuracy: 0.8043 - precision: 0.0407 - recall: 0.2978 - f1_score: 0.0716 - val_loss: 23.3654 - val_accuracy: 0.8565 - val_precision: 0.0408 - val_recall: 0.2960 - val_f1_score: 0.0716\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 1.1816 - accuracy: 0.7844 - precision: 0.0409 - recall: 0.2949 - f1_score: 0.0718 - val_loss: 3.1036 - val_accuracy: 0.8608 - val_precision: 0.0407 - val_recall: 0.2918 - val_f1_score: 0.0714\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 1.5804 - accuracy: 0.8370 - precision: 0.0406 - recall: 0.2900 - f1_score: 0.0713 - val_loss: 4.7522 - val_accuracy: 0.7384 - val_precision: 0.0408 - val_recall: 0.2887 - val_f1_score: 0.0715\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 1.3063 - accuracy: 0.8170 - precision: 0.0408 - recall: 0.2859 - f1_score: 0.0715 - val_loss: 4.2903 - val_accuracy: 0.8650 - val_precision: 0.0409 - val_recall: 0.2838 - val_f1_score: 0.0715\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.5835 - accuracy: 0.8243 - precision: 0.0411 - recall: 0.2820 - f1_score: 0.0717 - val_loss: 2.6966 - val_accuracy: 0.8481 - val_precision: 0.0412 - val_recall: 0.2801 - val_f1_score: 0.0719\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.5866 - accuracy: 0.8732 - precision: 0.0410 - recall: 0.2764 - f1_score: 0.0714 - val_loss: 2.4346 - val_accuracy: 0.8312 - val_precision: 0.0408 - val_recall: 0.2732 - val_f1_score: 0.0710\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.5449 - accuracy: 0.8641 - precision: 0.0410 - recall: 0.2716 - f1_score: 0.0713 - val_loss: 3.5360 - val_accuracy: 0.8481 - val_precision: 0.0410 - val_recall: 0.2689 - val_f1_score: 0.0712\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.5521 - accuracy: 0.8623 - precision: 0.0411 - recall: 0.2668 - f1_score: 0.0712 - val_loss: 1.6891 - val_accuracy: 0.8565 - val_precision: 0.0413 - val_recall: 0.2654 - val_f1_score: 0.0715\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3634 - accuracy: 0.9058 - precision: 0.0420 - recall: 0.2670 - f1_score: 0.0726 - val_loss: 3.3496 - val_accuracy: 0.8143 - val_precision: 0.0424 - val_recall: 0.2669 - val_f1_score: 0.0732\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.7240 - accuracy: 0.8768 - precision: 0.0432 - recall: 0.2699 - f1_score: 0.0745 - val_loss: 3.1359 - val_accuracy: 0.8143 - val_precision: 0.0435 - val_recall: 0.2702 - val_f1_score: 0.0749\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.9988 - accuracy: 0.8551 - precision: 0.0436 - recall: 0.2696 - f1_score: 0.0751 - val_loss: 7.4373 - val_accuracy: 0.7679 - val_precision: 0.0436 - val_recall: 0.2700 - val_f1_score: 0.0750\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.6185 - accuracy: 0.8496 - precision: 0.0439 - recall: 0.2711 - f1_score: 0.0756 - val_loss: 6.4802 - val_accuracy: 0.7553 - val_precision: 0.0440 - val_recall: 0.2713 - val_f1_score: 0.0758\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 1.1580 - accuracy: 0.8080 - precision: 0.0438 - recall: 0.2688 - f1_score: 0.0754 - val_loss: 45.7123 - val_accuracy: 0.7300 - val_precision: 0.0439 - val_recall: 0.2685 - val_f1_score: 0.0754\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.6867 - accuracy: 0.8080 - precision: 0.0438 - recall: 0.2679 - f1_score: 0.0752 - val_loss: 51.2392 - val_accuracy: 0.6203 - val_precision: 0.0440 - val_recall: 0.2688 - val_f1_score: 0.0757\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 2.0638 - accuracy: 0.8533 - precision: 0.0441 - recall: 0.2691 - f1_score: 0.0758 - val_loss: 73.0687 - val_accuracy: 0.8481 - val_precision: 0.0442 - val_recall: 0.2681 - val_f1_score: 0.0759\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 1.2755 - accuracy: 0.8804 - precision: 0.0446 - recall: 0.2686 - f1_score: 0.0765 - val_loss: 404.7088 - val_accuracy: 0.8650 - val_precision: 0.0450 - val_recall: 0.2685 - val_f1_score: 0.0771\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 3.2827 - accuracy: 0.8370 - precision: 0.0452 - recall: 0.2681 - f1_score: 0.0774 - val_loss: 134.3000 - val_accuracy: 0.8650 - val_precision: 0.0452 - val_recall: 0.2661 - val_f1_score: 0.0773\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 7.5855 - accuracy: 0.8333 - precision: 0.0451 - recall: 0.2648 - f1_score: 0.0771 - val_loss: 53.2873 - val_accuracy: 0.8650 - val_precision: 0.0452 - val_recall: 0.2647 - val_f1_score: 0.0772\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 3.8462 - accuracy: 0.7428 - precision: 0.0452 - recall: 0.2665 - f1_score: 0.0772 - val_loss: 20.4114 - val_accuracy: 0.3418 - val_precision: 0.0450 - val_recall: 0.2718 - val_f1_score: 0.0773\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 2.6460 - accuracy: 0.7899 - precision: 0.0448 - recall: 0.2751 - f1_score: 0.0770 - val_loss: 17.6994 - val_accuracy: 0.5865 - val_precision: 0.0446 - val_recall: 0.2748 - val_f1_score: 0.0768\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 188ms/step - loss: 2.4796 - accuracy: 0.7989 - precision: 0.0445 - recall: 0.2746 - f1_score: 0.0767 - val_loss: 31.8489 - val_accuracy: 0.8565 - val_precision: 0.0444 - val_recall: 0.2732 - val_f1_score: 0.0764\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 2.1551 - accuracy: 0.8080 - precision: 0.0444 - recall: 0.2724 - f1_score: 0.0764 - val_loss: 223.0526 - val_accuracy: 0.8650 - val_precision: 0.0447 - val_recall: 0.2722 - val_f1_score: 0.0768\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 2.4788 - accuracy: 0.8188 - precision: 0.0443 - recall: 0.2698 - f1_score: 0.0762 - val_loss: 243.5876 - val_accuracy: 0.8650 - val_precision: 0.0441 - val_recall: 0.2677 - val_f1_score: 0.0757\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.8347 - accuracy: 0.8333 - precision: 0.0441 - recall: 0.2665 - f1_score: 0.0756 - val_loss: 156.6163 - val_accuracy: 0.8439 - val_precision: 0.0440 - val_recall: 0.2673 - val_f1_score: 0.0756\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 1.4567 - accuracy: 0.7880 - precision: 0.0442 - recall: 0.2702 - f1_score: 0.0759 - val_loss: 58.8724 - val_accuracy: 0.7089 - val_precision: 0.0443 - val_recall: 0.2718 - val_f1_score: 0.0762\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 3.4646 - accuracy: 0.8043 - precision: 0.0444 - recall: 0.2726 - f1_score: 0.0763 - val_loss: 22.7392 - val_accuracy: 0.7764 - val_precision: 0.0445 - val_recall: 0.2730 - val_f1_score: 0.0766\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.6328 - accuracy: 0.7917 - precision: 0.0448 - recall: 0.2748 - f1_score: 0.0770 - val_loss: 20.0254 - val_accuracy: 0.7932 - val_precision: 0.0449 - val_recall: 0.2750 - val_f1_score: 0.0772\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.6163 - accuracy: 0.8025 - precision: 0.0447 - recall: 0.2743 - f1_score: 0.0769 - val_loss: 30.4720 - val_accuracy: 0.7511 - val_precision: 0.0446 - val_recall: 0.2744 - val_f1_score: 0.0767\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4539 - accuracy: 0.8514 - precision: 0.0448 - recall: 0.2750 - f1_score: 0.0770 - val_loss: 37.3472 - val_accuracy: 0.8439 - val_precision: 0.0449 - val_recall: 0.2746 - val_f1_score: 0.0772\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4014 - accuracy: 0.8750 - precision: 0.0451 - recall: 0.2741 - f1_score: 0.0774 - val_loss: 40.1207 - val_accuracy: 0.8481 - val_precision: 0.0452 - val_recall: 0.2733 - val_f1_score: 0.0776\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4095 - accuracy: 0.8551 - precision: 0.0456 - recall: 0.2737 - f1_score: 0.0781 - val_loss: 37.0861 - val_accuracy: 0.8608 - val_precision: 0.0456 - val_recall: 0.2727 - val_f1_score: 0.0782\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.5205 - accuracy: 0.8641 - precision: 0.0457 - recall: 0.2716 - f1_score: 0.0782 - val_loss: 7.5106 - val_accuracy: 0.8481 - val_precision: 0.0459 - val_recall: 0.2715 - val_f1_score: 0.0785\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.6882 - accuracy: 0.8406 - precision: 0.0460 - recall: 0.2709 - f1_score: 0.0787 - val_loss: 8.4601 - val_accuracy: 0.8565 - val_precision: 0.0462 - val_recall: 0.2704 - val_f1_score: 0.0788\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3524 - accuracy: 0.8750 - precision: 0.0465 - recall: 0.2710 - f1_score: 0.0793 - val_loss: 11.2576 - val_accuracy: 0.8523 - val_precision: 0.0470 - val_recall: 0.2727 - val_f1_score: 0.0801\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3737 - accuracy: 0.8714 - precision: 0.0473 - recall: 0.2734 - f1_score: 0.0806 - val_loss: 7.0072 - val_accuracy: 0.8439 - val_precision: 0.0476 - val_recall: 0.2739 - val_f1_score: 0.0811\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.4222 - accuracy: 0.8605 - precision: 0.0479 - recall: 0.2746 - f1_score: 0.0816 - val_loss: 11.4628 - val_accuracy: 0.8481 - val_precision: 0.0482 - val_recall: 0.2753 - val_f1_score: 0.0820\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3247 - accuracy: 0.8714 - precision: 0.0485 - recall: 0.2763 - f1_score: 0.0826 - val_loss: 9.2107 - val_accuracy: 0.8523 - val_precision: 0.0487 - val_recall: 0.2764 - val_f1_score: 0.0829\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3288 - accuracy: 0.8750 - precision: 0.0493 - recall: 0.2792 - f1_score: 0.0838 - val_loss: 9.7546 - val_accuracy: 0.8565 - val_precision: 0.0497 - val_recall: 0.2800 - val_f1_score: 0.0844\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.2635 - accuracy: 0.9004 - precision: 0.0503 - recall: 0.2824 - f1_score: 0.0854 - val_loss: 10.3144 - val_accuracy: 0.8439 - val_precision: 0.0505 - val_recall: 0.2833 - val_f1_score: 0.0857\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3539 - accuracy: 0.8804 - precision: 0.0508 - recall: 0.2845 - f1_score: 0.0862 - val_loss: 3.1958 - val_accuracy: 0.8565 - val_precision: 0.0514 - val_recall: 0.2869 - val_f1_score: 0.0872\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.8463 - accuracy: 0.8152 - precision: 0.0515 - recall: 0.2877 - f1_score: 0.0874 - val_loss: 4.1314 - val_accuracy: 0.8650 - val_precision: 0.0515 - val_recall: 0.2863 - val_f1_score: 0.0872\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 5.2884 - accuracy: 0.8370 - precision: 0.0514 - recall: 0.2853 - f1_score: 0.0871 - val_loss: 6.6707 - val_accuracy: 0.8228 - val_precision: 0.0514 - val_recall: 0.2839 - val_f1_score: 0.0871\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 2.3232 - accuracy: 0.7862 - precision: 0.0512 - recall: 0.2832 - f1_score: 0.0867 - val_loss: 12.0079 - val_accuracy: 0.8565 - val_precision: 0.0510 - val_recall: 0.2812 - val_f1_score: 0.0864\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.6846 - accuracy: 0.8587 - precision: 0.0512 - recall: 0.2808 - f1_score: 0.0866 - val_loss: 8.9631 - val_accuracy: 0.8523 - val_precision: 0.0511 - val_recall: 0.2789 - val_f1_score: 0.0864\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.6698 - accuracy: 0.8605 - precision: 0.0513 - recall: 0.2785 - f1_score: 0.0866 - val_loss: 2.7741 - val_accuracy: 0.7722 - val_precision: 0.0514 - val_recall: 0.2779 - val_f1_score: 0.0867\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.3475 - accuracy: 0.8587 - precision: 0.0516 - recall: 0.2782 - f1_score: 0.0871 - val_loss: 3.2902 - val_accuracy: 0.6498 - val_precision: 0.0516 - val_recall: 0.2774 - val_f1_score: 0.0871\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.9185 - accuracy: 0.8406 - precision: 0.0516 - recall: 0.2763 - f1_score: 0.0869 - val_loss: 12.7062 - val_accuracy: 0.8101 - val_precision: 0.0517 - val_recall: 0.2773 - val_f1_score: 0.0871\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 7.9089 - accuracy: 0.7482 - precision: 0.0513 - recall: 0.2779 - f1_score: 0.0866 - val_loss: 4.9220 - val_accuracy: 0.8565 - val_precision: 0.0510 - val_recall: 0.2769 - val_f1_score: 0.0861\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.9648 - accuracy: 0.8297 - precision: 0.0508 - recall: 0.2767 - f1_score: 0.0858 - val_loss: 4.4637 - val_accuracy: 0.8186 - val_precision: 0.0509 - val_recall: 0.2766 - val_f1_score: 0.0859\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 1.5012 - accuracy: 0.8225 - precision: 0.0509 - recall: 0.2771 - f1_score: 0.0860 - val_loss: 14.0136 - val_accuracy: 0.8439 - val_precision: 0.0508 - val_recall: 0.2778 - val_f1_score: 0.0859\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 188ms/step - loss: 0.6892 - accuracy: 0.7826 - precision: 0.0506 - recall: 0.2773 - f1_score: 0.0855 - val_loss: 27.4118 - val_accuracy: 0.8186 - val_precision: 0.0504 - val_recall: 0.2765 - val_f1_score: 0.0853\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.6044 - accuracy: 0.8333 - precision: 0.0505 - recall: 0.2770 - f1_score: 0.0854 - val_loss: 13.8404 - val_accuracy: 0.8270 - val_precision: 0.0504 - val_recall: 0.2771 - val_f1_score: 0.0853\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4686 - accuracy: 0.8370 - precision: 0.0504 - recall: 0.2760 - f1_score: 0.0852 - val_loss: 12.2109 - val_accuracy: 0.8143 - val_precision: 0.0504 - val_recall: 0.2756 - val_f1_score: 0.0852\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4149 - accuracy: 0.8605 - precision: 0.0504 - recall: 0.2750 - f1_score: 0.0851 - val_loss: 12.9032 - val_accuracy: 0.8270 - val_precision: 0.0502 - val_recall: 0.2740 - val_f1_score: 0.0849\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4541 - accuracy: 0.8551 - precision: 0.0503 - recall: 0.2742 - f1_score: 0.0850 - val_loss: 10.5778 - val_accuracy: 0.8101 - val_precision: 0.0504 - val_recall: 0.2743 - val_f1_score: 0.0852\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.4120 - accuracy: 0.8388 - precision: 0.0506 - recall: 0.2749 - f1_score: 0.0855 - val_loss: 5.6237 - val_accuracy: 0.8481 - val_precision: 0.0508 - val_recall: 0.2755 - val_f1_score: 0.0858\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.3260 - accuracy: 0.8569 - precision: 0.0510 - recall: 0.2769 - f1_score: 0.0862 - val_loss: 5.7020 - val_accuracy: 0.8143 - val_precision: 0.0511 - val_recall: 0.2772 - val_f1_score: 0.0863\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.3395 - accuracy: 0.8533 - precision: 0.0513 - recall: 0.2781 - f1_score: 0.0867 - val_loss: 5.9474 - val_accuracy: 0.8481 - val_precision: 0.0515 - val_recall: 0.2787 - val_f1_score: 0.0870\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.2929 - accuracy: 0.8732 - precision: 0.0516 - recall: 0.2788 - f1_score: 0.0871 - val_loss: 6.9603 - val_accuracy: 0.8228 - val_precision: 0.0518 - val_recall: 0.2787 - val_f1_score: 0.0873\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.3068 - accuracy: 0.8859 - precision: 0.0520 - recall: 0.2793 - f1_score: 0.0877 - val_loss: 5.3874 - val_accuracy: 0.8523 - val_precision: 0.0521 - val_recall: 0.2791 - val_f1_score: 0.0878\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.3074 - accuracy: 0.8931 - precision: 0.0523 - recall: 0.2800 - f1_score: 0.0882 - val_loss: 5.9521 - val_accuracy: 0.8608 - val_precision: 0.0527 - val_recall: 0.2809 - val_f1_score: 0.0887\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.1845 - accuracy: 0.8841 - precision: 0.0529 - recall: 0.2816 - f1_score: 0.0890 - val_loss: 5.0674 - val_accuracy: 0.8354 - val_precision: 0.0530 - val_recall: 0.2821 - val_f1_score: 0.0893\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.6463 - accuracy: 0.8460 - precision: 0.0531 - recall: 0.2832 - f1_score: 0.0894 - val_loss: 4.7793 - val_accuracy: 0.8650 - val_precision: 0.0531 - val_recall: 0.2831 - val_f1_score: 0.0894\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.7858 - accuracy: 0.8841 - precision: 0.0531 - recall: 0.2819 - f1_score: 0.0894 - val_loss: 9.3683 - val_accuracy: 0.8608 - val_precision: 0.0532 - val_recall: 0.2805 - val_f1_score: 0.0894\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.3667 - accuracy: 0.8786 - precision: 0.0533 - recall: 0.2801 - f1_score: 0.0895 - val_loss: 7.2057 - val_accuracy: 0.8650 - val_precision: 0.0532 - val_recall: 0.2792 - val_f1_score: 0.0894\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 1.4046 - accuracy: 0.8786 - precision: 0.0534 - recall: 0.2793 - f1_score: 0.0896 - val_loss: 1.0124 - val_accuracy: 0.8565 - val_precision: 0.0535 - val_recall: 0.2792 - val_f1_score: 0.0897\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.4336 - accuracy: 0.8986 - precision: 0.0536 - recall: 0.2792 - f1_score: 0.0900 - val_loss: 3.1324 - val_accuracy: 0.8101 - val_precision: 0.0538 - val_recall: 0.2796 - val_f1_score: 0.0903\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.5385 - accuracy: 0.8786 - precision: 0.0542 - recall: 0.2807 - f1_score: 0.0909 - val_loss: 4.2902 - val_accuracy: 0.8312 - val_precision: 0.0543 - val_recall: 0.2804 - val_f1_score: 0.0910\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.4655 - accuracy: 0.8786 - precision: 0.0545 - recall: 0.2808 - f1_score: 0.0913 - val_loss: 5.1900 - val_accuracy: 0.8439 - val_precision: 0.0546 - val_recall: 0.2804 - val_f1_score: 0.0915\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.4587 - accuracy: 0.8949 - precision: 0.0548 - recall: 0.2801 - f1_score: 0.0916 - val_loss: 4.1319 - val_accuracy: 0.8608 - val_precision: 0.0550 - val_recall: 0.2800 - val_f1_score: 0.0919\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.5058 - accuracy: 0.8967 - precision: 0.0551 - recall: 0.2798 - f1_score: 0.0921 - val_loss: 2.9553 - val_accuracy: 0.8650 - val_precision: 0.0552 - val_recall: 0.2792 - val_f1_score: 0.0922\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3672 - accuracy: 0.9130 - precision: 0.0554 - recall: 0.2791 - f1_score: 0.0924 - val_loss: 2.5121 - val_accuracy: 0.8650 - val_precision: 0.0555 - val_recall: 0.2788 - val_f1_score: 0.0926\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.2849 - accuracy: 0.9112 - precision: 0.0557 - recall: 0.2789 - f1_score: 0.0928 - val_loss: 2.7951 - val_accuracy: 0.8523 - val_precision: 0.0558 - val_recall: 0.2785 - val_f1_score: 0.0929\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2060 - accuracy: 0.9384 - precision: 0.0560 - recall: 0.2789 - f1_score: 0.0933 - val_loss: 2.8607 - val_accuracy: 0.8523 - val_precision: 0.0564 - val_recall: 0.2796 - val_f1_score: 0.0938\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2104 - accuracy: 0.9438 - precision: 0.0569 - recall: 0.2816 - f1_score: 0.0947 - val_loss: 3.1166 - val_accuracy: 0.8439 - val_precision: 0.0572 - val_recall: 0.2819 - val_f1_score: 0.0950\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3187 - accuracy: 0.9348 - precision: 0.0574 - recall: 0.2829 - f1_score: 0.0954 - val_loss: 3.6462 - val_accuracy: 0.8692 - val_precision: 0.0577 - val_recall: 0.2837 - val_f1_score: 0.0959\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.7430 - accuracy: 0.9040 - precision: 0.0578 - recall: 0.2844 - f1_score: 0.0961 - val_loss: 3.1609 - val_accuracy: 0.8354 - val_precision: 0.0582 - val_recall: 0.2855 - val_f1_score: 0.0967\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 2.6665 - accuracy: 0.8714 - precision: 0.0586 - recall: 0.2870 - f1_score: 0.0974 - val_loss: 3.0142 - val_accuracy: 0.8650 - val_precision: 0.0588 - val_recall: 0.2871 - val_f1_score: 0.0976\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 3.3669 - accuracy: 0.8623 - precision: 0.0588 - recall: 0.2868 - f1_score: 0.0976 - val_loss: 406.5887 - val_accuracy: 0.8523 - val_precision: 0.0590 - val_recall: 0.2871 - val_f1_score: 0.0979\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.3492 - accuracy: 0.8623 - precision: 0.0593 - recall: 0.2880 - f1_score: 0.0983 - val_loss: 601.1859 - val_accuracy: 0.6751 - val_precision: 0.0594 - val_recall: 0.2877 - val_f1_score: 0.0985\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 185ms/step - loss: 1.4401 - accuracy: 0.8714 - precision: 0.0594 - recall: 0.2873 - f1_score: 0.0984 - val_loss: 134.5580 - val_accuracy: 0.8523 - val_precision: 0.0594 - val_recall: 0.2873 - val_f1_score: 0.0985\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 1.0295 - accuracy: 0.8478 - precision: 0.0596 - recall: 0.2876 - f1_score: 0.0987 - val_loss: 18.8330 - val_accuracy: 0.8650 - val_precision: 0.0596 - val_recall: 0.2872 - val_f1_score: 0.0988\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.5520 - accuracy: 0.8659 - precision: 0.0598 - recall: 0.2871 - f1_score: 0.0990 - val_loss: 6.7882 - val_accuracy: 0.8692 - val_precision: 0.0598 - val_recall: 0.2861 - val_f1_score: 0.0989\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.5297 - accuracy: 0.8786 - precision: 0.0600 - recall: 0.2860 - f1_score: 0.0991 - val_loss: 13.3810 - val_accuracy: 0.8692 - val_precision: 0.0601 - val_recall: 0.2857 - val_f1_score: 0.0993\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.6901 - accuracy: 0.8514 - precision: 0.0602 - recall: 0.2855 - f1_score: 0.0994 - val_loss: 24.1759 - val_accuracy: 0.8186 - val_precision: 0.0602 - val_recall: 0.2847 - val_f1_score: 0.0993\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 4.0202 - accuracy: 0.8659 - precision: 0.0602 - recall: 0.2847 - f1_score: 0.0994 - val_loss: 157.2267 - val_accuracy: 0.4599 - val_precision: 0.0603 - val_recall: 0.2842 - val_f1_score: 0.0995\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.3317 - accuracy: 0.8351 - precision: 0.0604 - recall: 0.2839 - f1_score: 0.0996 - val_loss: 208.8287 - val_accuracy: 0.8523 - val_precision: 0.0604 - val_recall: 0.2832 - val_f1_score: 0.0995\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.7072 - accuracy: 0.8315 - precision: 0.0603 - recall: 0.2831 - f1_score: 0.0995 - val_loss: 154.9248 - val_accuracy: 0.4346 - val_precision: 0.0602 - val_recall: 0.2824 - val_f1_score: 0.0992\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.4392 - accuracy: 0.8243 - precision: 0.0601 - recall: 0.2822 - f1_score: 0.0991 - val_loss: 245.6145 - val_accuracy: 0.8481 - val_precision: 0.0600 - val_recall: 0.2814 - val_f1_score: 0.0989\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 2.1294 - accuracy: 0.8243 - precision: 0.0599 - recall: 0.2810 - f1_score: 0.0987 - val_loss: 32.7664 - val_accuracy: 0.1857 - val_precision: 0.0598 - val_recall: 0.2803 - val_f1_score: 0.0986\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.0893 - accuracy: 0.8152 - precision: 0.0598 - recall: 0.2802 - f1_score: 0.0986 - val_loss: 18.2074 - val_accuracy: 0.7046 - val_precision: 0.0597 - val_recall: 0.2804 - val_f1_score: 0.0985\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.2280 - accuracy: 0.8406 - precision: 0.0596 - recall: 0.2801 - f1_score: 0.0983 - val_loss: 48.0380 - val_accuracy: 0.7595 - val_precision: 0.0596 - val_recall: 0.2794 - val_f1_score: 0.0982\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4313 - accuracy: 0.8822 - precision: 0.0597 - recall: 0.2798 - f1_score: 0.0984 - val_loss: 23.1661 - val_accuracy: 0.8481 - val_precision: 0.0598 - val_recall: 0.2797 - val_f1_score: 0.0986\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3714 - accuracy: 0.8949 - precision: 0.0599 - recall: 0.2802 - f1_score: 0.0988 - val_loss: 22.6530 - val_accuracy: 0.6793 - val_precision: 0.0599 - val_recall: 0.2800 - val_f1_score: 0.0988\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.5598 - accuracy: 0.8967 - precision: 0.0601 - recall: 0.2804 - f1_score: 0.0990 - val_loss: 24.3924 - val_accuracy: 0.7004 - val_precision: 0.0602 - val_recall: 0.2797 - val_f1_score: 0.0991\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.9156 - accuracy: 0.8786 - precision: 0.0603 - recall: 0.2798 - f1_score: 0.0992 - val_loss: 95.3001 - val_accuracy: 0.8523 - val_precision: 0.0604 - val_recall: 0.2797 - val_f1_score: 0.0994\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5209 - accuracy: 0.8895 - precision: 0.0603 - recall: 0.2793 - f1_score: 0.0992 - val_loss: 135.7141 - val_accuracy: 0.8650 - val_precision: 0.0603 - val_recall: 0.2791 - val_f1_score: 0.0991\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4555 - accuracy: 0.9004 - precision: 0.0603 - recall: 0.2795 - f1_score: 0.0991 - val_loss: 109.2289 - val_accuracy: 0.8565 - val_precision: 0.0602 - val_recall: 0.2797 - val_f1_score: 0.0991\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2889 - accuracy: 0.9203 - precision: 0.0601 - recall: 0.2801 - f1_score: 0.0989 - val_loss: 98.9359 - val_accuracy: 0.8565 - val_precision: 0.0602 - val_recall: 0.2810 - val_f1_score: 0.0991\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3285 - accuracy: 0.9167 - precision: 0.0601 - recall: 0.2814 - f1_score: 0.0990 - val_loss: 88.9335 - val_accuracy: 0.8523 - val_precision: 0.0602 - val_recall: 0.2814 - val_f1_score: 0.0992\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6421 - accuracy: 0.9221 - precision: 0.0603 - recall: 0.2825 - f1_score: 0.0994 - val_loss: 72.2693 - val_accuracy: 0.8565 - val_precision: 0.0604 - val_recall: 0.2828 - val_f1_score: 0.0996\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6308 - accuracy: 0.8986 - precision: 0.0605 - recall: 0.2831 - f1_score: 0.0997 - val_loss: 24.3061 - val_accuracy: 0.8650 - val_precision: 0.0606 - val_recall: 0.2840 - val_f1_score: 0.0999\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.7417 - accuracy: 0.8714 - precision: 0.0607 - recall: 0.2851 - f1_score: 0.1000 - val_loss: 30.5318 - val_accuracy: 0.8692 - val_precision: 0.0606 - val_recall: 0.2853 - val_f1_score: 0.1000\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.2729 - accuracy: 0.8931 - precision: 0.0608 - recall: 0.2862 - f1_score: 0.1004 - val_loss: 30.1511 - val_accuracy: 0.8608 - val_precision: 0.0608 - val_recall: 0.2863 - val_f1_score: 0.1004\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6651 - accuracy: 0.8659 - precision: 0.0608 - recall: 0.2860 - f1_score: 0.1003 - val_loss: 29.3164 - val_accuracy: 0.8650 - val_precision: 0.0608 - val_recall: 0.2855 - val_f1_score: 0.1003\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5619 - accuracy: 0.8605 - precision: 0.0610 - recall: 0.2860 - f1_score: 0.1006 - val_loss: 44.2391 - val_accuracy: 0.8734 - val_precision: 0.0611 - val_recall: 0.2860 - val_f1_score: 0.1007\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4260 - accuracy: 0.8877 - precision: 0.0612 - recall: 0.2867 - f1_score: 0.1009 - val_loss: 39.3109 - val_accuracy: 0.8734 - val_precision: 0.0613 - val_recall: 0.2869 - val_f1_score: 0.1010\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.2562 - accuracy: 0.8895 - precision: 0.0614 - recall: 0.2871 - f1_score: 0.1011 - val_loss: 35.6005 - val_accuracy: 0.8776 - val_precision: 0.0615 - val_recall: 0.2873 - val_f1_score: 0.1013\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.5472 - accuracy: 0.8804 - precision: 0.0616 - recall: 0.2877 - f1_score: 0.1015 - val_loss: 48.2590 - val_accuracy: 0.8692 - val_precision: 0.0616 - val_recall: 0.2873 - val_f1_score: 0.1014\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6343 - accuracy: 0.8514 - precision: 0.0617 - recall: 0.2874 - f1_score: 0.1016 - val_loss: 55.2520 - val_accuracy: 0.8565 - val_precision: 0.0619 - val_recall: 0.2871 - val_f1_score: 0.1018\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 178ms/step - loss: 1.9364 - accuracy: 0.8931 - precision: 0.0620 - recall: 0.2877 - f1_score: 0.1021 - val_loss: 36.0143 - val_accuracy: 0.8650 - val_precision: 0.0622 - val_recall: 0.2875 - val_f1_score: 0.1022\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6884 - accuracy: 0.8750 - precision: 0.0622 - recall: 0.2870 - f1_score: 0.1023 - val_loss: 15.0979 - val_accuracy: 0.8439 - val_precision: 0.0622 - val_recall: 0.2866 - val_f1_score: 0.1023\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.0965 - accuracy: 0.8714 - precision: 0.0623 - recall: 0.2862 - f1_score: 0.1023 - val_loss: 24.6340 - val_accuracy: 0.8186 - val_precision: 0.0624 - val_recall: 0.2863 - val_f1_score: 0.1025\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4379 - accuracy: 0.8931 - precision: 0.0625 - recall: 0.2870 - f1_score: 0.1027 - val_loss: 38.1270 - val_accuracy: 0.8101 - val_precision: 0.0627 - val_recall: 0.2874 - val_f1_score: 0.1030\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4310 - accuracy: 0.8967 - precision: 0.0630 - recall: 0.2885 - f1_score: 0.1035 - val_loss: 43.5538 - val_accuracy: 0.8228 - val_precision: 0.0631 - val_recall: 0.2884 - val_f1_score: 0.1036\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 4.6887 - accuracy: 0.8967 - precision: 0.0632 - recall: 0.2882 - f1_score: 0.1036 - val_loss: 7.4827 - val_accuracy: 0.8354 - val_precision: 0.0632 - val_recall: 0.2881 - val_f1_score: 0.1036\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.3143 - accuracy: 0.8822 - precision: 0.0632 - recall: 0.2891 - f1_score: 0.1037 - val_loss: 27.1445 - val_accuracy: 0.8692 - val_precision: 0.0632 - val_recall: 0.2892 - val_f1_score: 0.1037\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.5370 - accuracy: 0.8986 - precision: 0.0632 - recall: 0.2893 - f1_score: 0.1038 - val_loss: 39.4952 - val_accuracy: 0.8565 - val_precision: 0.0633 - val_recall: 0.2896 - val_f1_score: 0.1039\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 4.2809 - accuracy: 0.8841 - precision: 0.0634 - recall: 0.2897 - f1_score: 0.1040 - val_loss: 21.4802 - val_accuracy: 0.8523 - val_precision: 0.0635 - val_recall: 0.2898 - val_f1_score: 0.1042\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6338 - accuracy: 0.8986 - precision: 0.0637 - recall: 0.2905 - f1_score: 0.1045 - val_loss: 18.7881 - val_accuracy: 0.8608 - val_precision: 0.0637 - val_recall: 0.2905 - val_f1_score: 0.1045\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6446 - accuracy: 0.8931 - precision: 0.0639 - recall: 0.2903 - f1_score: 0.1047 - val_loss: 16.3404 - val_accuracy: 0.7046 - val_precision: 0.0639 - val_recall: 0.2902 - val_f1_score: 0.1048\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.1839 - accuracy: 0.9004 - precision: 0.0641 - recall: 0.2904 - f1_score: 0.1050 - val_loss: 7.7358 - val_accuracy: 0.8650 - val_precision: 0.0642 - val_recall: 0.2901 - val_f1_score: 0.1051\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.0611 - accuracy: 0.8931 - precision: 0.0642 - recall: 0.2905 - f1_score: 0.1052 - val_loss: 1.7453 - val_accuracy: 0.8608 - val_precision: 0.0642 - val_recall: 0.2906 - val_f1_score: 0.1052\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.2018 - accuracy: 0.8225 - precision: 0.0640 - recall: 0.2909 - f1_score: 0.1049 - val_loss: 2.1081 - val_accuracy: 0.8439 - val_precision: 0.0635 - val_recall: 0.2916 - val_f1_score: 0.1043\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.7018 - accuracy: 0.8822 - precision: 0.0633 - recall: 0.2925 - f1_score: 0.1041 - val_loss: 1.9193 - val_accuracy: 0.8650 - val_precision: 0.0634 - val_recall: 0.2922 - val_f1_score: 0.1042\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4662 - accuracy: 0.8877 - precision: 0.0633 - recall: 0.2920 - f1_score: 0.1040 - val_loss: 3.1025 - val_accuracy: 0.8439 - val_precision: 0.0632 - val_recall: 0.2914 - val_f1_score: 0.1039\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3381 - accuracy: 0.9185 - precision: 0.0634 - recall: 0.2918 - f1_score: 0.1041 - val_loss: 4.0285 - val_accuracy: 0.8439 - val_precision: 0.0634 - val_recall: 0.2913 - val_f1_score: 0.1042\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.7152 - accuracy: 0.9040 - precision: 0.0635 - recall: 0.2914 - f1_score: 0.1043 - val_loss: 3.7725 - val_accuracy: 0.7300 - val_precision: 0.0637 - val_recall: 0.2916 - val_f1_score: 0.1046\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.4463 - accuracy: 0.8496 - precision: 0.0637 - recall: 0.2920 - f1_score: 0.1046 - val_loss: 3.8964 - val_accuracy: 0.8397 - val_precision: 0.0638 - val_recall: 0.2924 - val_f1_score: 0.1047\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3278 - accuracy: 0.9076 - precision: 0.0640 - recall: 0.2930 - f1_score: 0.1050 - val_loss: 10.9999 - val_accuracy: 0.8523 - val_precision: 0.0641 - val_recall: 0.2929 - val_f1_score: 0.1052\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.8039 - accuracy: 0.9040 - precision: 0.0642 - recall: 0.2931 - f1_score: 0.1053 - val_loss: 10.8960 - val_accuracy: 0.8439 - val_precision: 0.0644 - val_recall: 0.2933 - val_f1_score: 0.1056\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 2.3946 - accuracy: 0.8659 - precision: 0.0644 - recall: 0.2933 - f1_score: 0.1057 - val_loss: 5.2270 - val_accuracy: 0.8228 - val_precision: 0.0646 - val_recall: 0.2941 - val_f1_score: 0.1060\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 3.5073 - accuracy: 0.8569 - precision: 0.0646 - recall: 0.2943 - f1_score: 0.1060 - val_loss: 21.4425 - val_accuracy: 0.8481 - val_precision: 0.0648 - val_recall: 0.2947 - val_f1_score: 0.1062\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6436 - accuracy: 0.8659 - precision: 0.0649 - recall: 0.2949 - f1_score: 0.1064 - val_loss: 22.1860 - val_accuracy: 0.8397 - val_precision: 0.0650 - val_recall: 0.2950 - val_f1_score: 0.1066\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 1.7531 - accuracy: 0.8496 - precision: 0.0651 - recall: 0.2951 - f1_score: 0.1067 - val_loss: 41.9833 - val_accuracy: 0.8523 - val_precision: 0.0652 - val_recall: 0.2952 - val_f1_score: 0.1069\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 2.1923 - accuracy: 0.8913 - precision: 0.0654 - recall: 0.2954 - f1_score: 0.1071 - val_loss: 13.2055 - val_accuracy: 0.8608 - val_precision: 0.0654 - val_recall: 0.2951 - val_f1_score: 0.1071\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 0.8836 - accuracy: 0.8605 - precision: 0.0655 - recall: 0.2946 - f1_score: 0.1072 - val_loss: 7.4947 - val_accuracy: 0.8650 - val_precision: 0.0655 - val_recall: 0.2943 - val_f1_score: 0.1071\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6211 - accuracy: 0.8841 - precision: 0.0655 - recall: 0.2939 - f1_score: 0.1072 - val_loss: 5.7063 - val_accuracy: 0.8650 - val_precision: 0.0656 - val_recall: 0.2937 - val_f1_score: 0.1073\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 2.4655 - accuracy: 0.8804 - precision: 0.0657 - recall: 0.2935 - f1_score: 0.1074 - val_loss: 6.0770 - val_accuracy: 0.6709 - val_precision: 0.0658 - val_recall: 0.2931 - val_f1_score: 0.1075\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 5.8469 - accuracy: 0.9112 - precision: 0.0660 - recall: 0.2934 - f1_score: 0.1077 - val_loss: 5.2127 - val_accuracy: 0.6540 - val_precision: 0.0660 - val_recall: 0.2930 - val_f1_score: 0.1078\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 178ms/step - loss: 5.7833 - accuracy: 0.8750 - precision: 0.0660 - recall: 0.2929 - f1_score: 0.1078 - val_loss: 4.4666 - val_accuracy: 0.8565 - val_precision: 0.0661 - val_recall: 0.2928 - val_f1_score: 0.1079\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 8.8309 - accuracy: 0.8551 - precision: 0.0663 - recall: 0.2934 - f1_score: 0.1082 - val_loss: 10.4774 - val_accuracy: 0.8565 - val_precision: 0.0664 - val_recall: 0.2933 - val_f1_score: 0.1083\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 11.2018 - accuracy: 0.8641 - precision: 0.0666 - recall: 0.2942 - f1_score: 0.1086 - val_loss: 6.0920 - val_accuracy: 0.8650 - val_precision: 0.0665 - val_recall: 0.2942 - val_f1_score: 0.1085\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 3.2982 - accuracy: 0.8370 - precision: 0.0665 - recall: 0.2937 - f1_score: 0.1084 - val_loss: 1.8937 - val_accuracy: 0.8439 - val_precision: 0.0664 - val_recall: 0.2932 - val_f1_score: 0.1083\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6839 - accuracy: 0.8732 - precision: 0.0664 - recall: 0.2930 - f1_score: 0.1083 - val_loss: 1.8571 - val_accuracy: 0.8312 - val_precision: 0.0664 - val_recall: 0.2928 - val_f1_score: 0.1083\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.4054 - accuracy: 0.8804 - precision: 0.0666 - recall: 0.2933 - f1_score: 0.1085 - val_loss: 2.6185 - val_accuracy: 0.8354 - val_precision: 0.0665 - val_recall: 0.2933 - val_f1_score: 0.1085\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 4.3338 - accuracy: 0.8696 - precision: 0.0667 - recall: 0.2938 - f1_score: 0.1087 - val_loss: 6.1777 - val_accuracy: 0.8650 - val_precision: 0.0667 - val_recall: 0.2939 - val_f1_score: 0.1088\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 3.8829 - accuracy: 0.8170 - precision: 0.0668 - recall: 0.2944 - f1_score: 0.1088 - val_loss: 39.1617 - val_accuracy: 0.3249 - val_precision: 0.0667 - val_recall: 0.2945 - val_f1_score: 0.1088\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.2006 - accuracy: 0.8406 - precision: 0.0667 - recall: 0.2942 - f1_score: 0.1088 - val_loss: 4.2010 - val_accuracy: 0.7848 - val_precision: 0.0667 - val_recall: 0.2943 - val_f1_score: 0.1087\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.8969 - accuracy: 0.8605 - precision: 0.0667 - recall: 0.2950 - f1_score: 0.1088 - val_loss: 4.1511 - val_accuracy: 0.8228 - val_precision: 0.0668 - val_recall: 0.2956 - val_f1_score: 0.1090\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 3.7218 - accuracy: 0.8569 - precision: 0.0668 - recall: 0.2955 - f1_score: 0.1089 - val_loss: 12.2222 - val_accuracy: 0.7848 - val_precision: 0.0667 - val_recall: 0.2956 - val_f1_score: 0.1089\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.9190 - accuracy: 0.8424 - precision: 0.0669 - recall: 0.2961 - f1_score: 0.1091 - val_loss: 17.1680 - val_accuracy: 0.7173 - val_precision: 0.0669 - val_recall: 0.2960 - val_f1_score: 0.1092\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 3.3871 - accuracy: 0.8732 - precision: 0.0670 - recall: 0.2958 - f1_score: 0.1092 - val_loss: 7.2082 - val_accuracy: 0.7848 - val_precision: 0.0669 - val_recall: 0.2954 - val_f1_score: 0.1092\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.0147 - accuracy: 0.8732 - precision: 0.0669 - recall: 0.2950 - f1_score: 0.1090 - val_loss: 6.9884 - val_accuracy: 0.8186 - val_precision: 0.0668 - val_recall: 0.2950 - val_f1_score: 0.1089\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.6888 - accuracy: 0.8551 - precision: 0.0668 - recall: 0.2952 - f1_score: 0.1089 - val_loss: 8.3878 - val_accuracy: 0.7932 - val_precision: 0.0667 - val_recall: 0.2950 - val_f1_score: 0.1089\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.5338 - accuracy: 0.9167 - precision: 0.0669 - recall: 0.2952 - f1_score: 0.1091 - val_loss: 8.8555 - val_accuracy: 0.8481 - val_precision: 0.0670 - val_recall: 0.2952 - val_f1_score: 0.1092\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6840 - accuracy: 0.9058 - precision: 0.0672 - recall: 0.2957 - f1_score: 0.1096 - val_loss: 10.5942 - val_accuracy: 0.8650 - val_precision: 0.0673 - val_recall: 0.2953 - val_f1_score: 0.1096\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.3765 - accuracy: 0.9022 - precision: 0.0674 - recall: 0.2957 - f1_score: 0.1098 - val_loss: 13.3322 - val_accuracy: 0.8565 - val_precision: 0.0675 - val_recall: 0.2956 - val_f1_score: 0.1100\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4609 - accuracy: 0.9004 - precision: 0.0676 - recall: 0.2956 - f1_score: 0.1100 - val_loss: 15.4922 - val_accuracy: 0.8565 - val_precision: 0.0677 - val_recall: 0.2952 - val_f1_score: 0.1101\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.2349 - accuracy: 0.9221 - precision: 0.0678 - recall: 0.2960 - f1_score: 0.1103 - val_loss: 16.6602 - val_accuracy: 0.8481 - val_precision: 0.0678 - val_recall: 0.2962 - val_f1_score: 0.1103\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.2592 - accuracy: 0.9239 - precision: 0.0679 - recall: 0.2965 - f1_score: 0.1105 - val_loss: 16.1154 - val_accuracy: 0.8439 - val_precision: 0.0680 - val_recall: 0.2966 - val_f1_score: 0.1107\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.2962 - accuracy: 0.9257 - precision: 0.0682 - recall: 0.2972 - f1_score: 0.1109 - val_loss: 15.5134 - val_accuracy: 0.8354 - val_precision: 0.0683 - val_recall: 0.2976 - val_f1_score: 0.1111\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2530 - accuracy: 0.9257 - precision: 0.0685 - recall: 0.2982 - f1_score: 0.1115 - val_loss: 16.4065 - val_accuracy: 0.8481 - val_precision: 0.0686 - val_recall: 0.2981 - val_f1_score: 0.1116\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4918 - accuracy: 0.9257 - precision: 0.0688 - recall: 0.2985 - f1_score: 0.1118 - val_loss: 17.5977 - val_accuracy: 0.8650 - val_precision: 0.0690 - val_recall: 0.2989 - val_f1_score: 0.1121\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.2137 - accuracy: 0.9348 - precision: 0.0692 - recall: 0.2997 - f1_score: 0.1124 - val_loss: 15.3945 - val_accuracy: 0.8608 - val_precision: 0.0694 - val_recall: 0.3000 - val_f1_score: 0.1127\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.2208 - accuracy: 0.9257 - precision: 0.0697 - recall: 0.3007 - f1_score: 0.1131 - val_loss: 14.4484 - val_accuracy: 0.8481 - val_precision: 0.0698 - val_recall: 0.3009 - val_f1_score: 0.1133\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.2301 - accuracy: 0.9402 - precision: 0.0700 - recall: 0.3014 - f1_score: 0.1136 - val_loss: 14.4040 - val_accuracy: 0.8650 - val_precision: 0.0701 - val_recall: 0.3014 - val_f1_score: 0.1137\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2125 - accuracy: 0.9475 - precision: 0.0703 - recall: 0.3020 - f1_score: 0.1140 - val_loss: 13.7344 - val_accuracy: 0.8650 - val_precision: 0.0705 - val_recall: 0.3023 - val_f1_score: 0.1143\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.1894 - accuracy: 0.9366 - precision: 0.0706 - recall: 0.3028 - f1_score: 0.1146 - val_loss: 13.3879 - val_accuracy: 0.8439 - val_precision: 0.0708 - val_recall: 0.3030 - val_f1_score: 0.1148\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.2663 - accuracy: 0.9402 - precision: 0.0711 - recall: 0.3038 - f1_score: 0.1152 - val_loss: 13.1252 - val_accuracy: 0.8143 - val_precision: 0.0712 - val_recall: 0.3043 - val_f1_score: 0.1154\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 184ms/step - loss: 0.3761 - accuracy: 0.9420 - precision: 0.0715 - recall: 0.3052 - f1_score: 0.1158 - val_loss: 11.7378 - val_accuracy: 0.8734 - val_precision: 0.0716 - val_recall: 0.3056 - val_f1_score: 0.1161\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.2972 - accuracy: 0.9257 - precision: 0.0718 - recall: 0.3062 - f1_score: 0.1163 - val_loss: 11.7005 - val_accuracy: 0.8523 - val_precision: 0.0719 - val_recall: 0.3065 - val_f1_score: 0.1164\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1556 - accuracy: 0.9529 - precision: 0.0720 - recall: 0.3071 - f1_score: 0.1167 - val_loss: 14.1278 - val_accuracy: 0.8523 - val_precision: 0.0722 - val_recall: 0.3075 - val_f1_score: 0.1169\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.4197 - accuracy: 0.9384 - precision: 0.0724 - recall: 0.3083 - f1_score: 0.1173 - val_loss: 25.1100 - val_accuracy: 0.8523 - val_precision: 0.0724 - val_recall: 0.3084 - val_f1_score: 0.1173\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 2.8428 - accuracy: 0.8750 - precision: 0.0725 - recall: 0.3087 - f1_score: 0.1174 - val_loss: 49.1216 - val_accuracy: 0.1772 - val_precision: 0.0724 - val_recall: 0.3081 - val_f1_score: 0.1173\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 2.7035 - accuracy: 0.8424 - precision: 0.0724 - recall: 0.3082 - f1_score: 0.1172 - val_loss: 32.5851 - val_accuracy: 0.8608 - val_precision: 0.0724 - val_recall: 0.3081 - val_f1_score: 0.1172\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 4.5408 - accuracy: 0.8587 - precision: 0.0724 - recall: 0.3082 - f1_score: 0.1173 - val_loss: 122.6171 - val_accuracy: 0.8650 - val_precision: 0.0724 - val_recall: 0.3078 - val_f1_score: 0.1173\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 5.2441 - accuracy: 0.8913 - precision: 0.0725 - recall: 0.3076 - f1_score: 0.1173 - val_loss: 8.2763 - val_accuracy: 0.5992 - val_precision: 0.0725 - val_recall: 0.3077 - val_f1_score: 0.1174\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.5202 - accuracy: 0.8659 - precision: 0.0726 - recall: 0.3075 - f1_score: 0.1174 - val_loss: 3.4769 - val_accuracy: 0.8481 - val_precision: 0.0726 - val_recall: 0.3073 - val_f1_score: 0.1175\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.5597 - accuracy: 0.8659 - precision: 0.0727 - recall: 0.3074 - f1_score: 0.1176 - val_loss: 8.8131 - val_accuracy: 0.8650 - val_precision: 0.0728 - val_recall: 0.3074 - val_f1_score: 0.1177\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.5843 - accuracy: 0.8841 - precision: 0.0729 - recall: 0.3074 - f1_score: 0.1179 - val_loss: 6.6737 - val_accuracy: 0.8608 - val_precision: 0.0729 - val_recall: 0.3071 - val_f1_score: 0.1179\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 2.4210 - accuracy: 0.8877 - precision: 0.0729 - recall: 0.3068 - f1_score: 0.1178 - val_loss: 2.2764 - val_accuracy: 0.6118 - val_precision: 0.0729 - val_recall: 0.3064 - val_f1_score: 0.1178\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.2107 - accuracy: 0.8822 - precision: 0.0730 - recall: 0.3061 - f1_score: 0.1179 - val_loss: 1.7707 - val_accuracy: 0.8608 - val_precision: 0.0730 - val_recall: 0.3058 - val_f1_score: 0.1179\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.7862 - accuracy: 0.8841 - precision: 0.0731 - recall: 0.3059 - f1_score: 0.1181 - val_loss: 2.1160 - val_accuracy: 0.8608 - val_precision: 0.0731 - val_recall: 0.3056 - val_f1_score: 0.1180\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4573 - accuracy: 0.9004 - precision: 0.0733 - recall: 0.3059 - f1_score: 0.1182 - val_loss: 1.8910 - val_accuracy: 0.8523 - val_precision: 0.0734 - val_recall: 0.3057 - val_f1_score: 0.1183\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4146 - accuracy: 0.9130 - precision: 0.0735 - recall: 0.3058 - f1_score: 0.1185 - val_loss: 1.8772 - val_accuracy: 0.8523 - val_precision: 0.0736 - val_recall: 0.3058 - val_f1_score: 0.1187\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.4291 - accuracy: 0.9058 - precision: 0.0738 - recall: 0.3058 - f1_score: 0.1188 - val_loss: 2.1030 - val_accuracy: 0.8565 - val_precision: 0.0739 - val_recall: 0.3055 - val_f1_score: 0.1189\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3631 - accuracy: 0.9221 - precision: 0.0740 - recall: 0.3056 - f1_score: 0.1192 - val_loss: 1.7403 - val_accuracy: 0.8692 - val_precision: 0.0742 - val_recall: 0.3057 - val_f1_score: 0.1194\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.4754 - accuracy: 0.9076 - precision: 0.0744 - recall: 0.3063 - f1_score: 0.1198 - val_loss: 1.9202 - val_accuracy: 0.8692 - val_precision: 0.0746 - val_recall: 0.3063 - val_f1_score: 0.1200\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.3579 - accuracy: 0.9221 - precision: 0.0747 - recall: 0.3061 - f1_score: 0.1201 - val_loss: 1.9306 - val_accuracy: 0.8692 - val_precision: 0.0748 - val_recall: 0.3059 - val_f1_score: 0.1202\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.4967 - accuracy: 0.9312 - precision: 0.0750 - recall: 0.3064 - f1_score: 0.1205 - val_loss: 1.8391 - val_accuracy: 0.8650 - val_precision: 0.0752 - val_recall: 0.3066 - val_f1_score: 0.1208\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4094 - accuracy: 0.9312 - precision: 0.0754 - recall: 0.3069 - f1_score: 0.1210 - val_loss: 2.0344 - val_accuracy: 0.8565 - val_precision: 0.0755 - val_recall: 0.3068 - val_f1_score: 0.1212\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.5235 - accuracy: 0.9312 - precision: 0.0757 - recall: 0.3072 - f1_score: 0.1215 - val_loss: 1.7980 - val_accuracy: 0.8692 - val_precision: 0.0759 - val_recall: 0.3074 - val_f1_score: 0.1217\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 1.1539 - accuracy: 0.9004 - precision: 0.0761 - recall: 0.3077 - f1_score: 0.1220 - val_loss: 1.8352 - val_accuracy: 0.8692 - val_precision: 0.0762 - val_recall: 0.3077 - val_f1_score: 0.1221\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1035 - accuracy: 0.8931 - precision: 0.0763 - recall: 0.3076 - f1_score: 0.1222 - val_loss: 1.6575 - val_accuracy: 0.8734 - val_precision: 0.0764 - val_recall: 0.3074 - val_f1_score: 0.1224\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.4991 - accuracy: 0.9149 - precision: 0.0765 - recall: 0.3077 - f1_score: 0.1226 - val_loss: 1.2485 - val_accuracy: 0.8692 - val_precision: 0.0767 - val_recall: 0.3079 - val_f1_score: 0.1228\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2783 - accuracy: 0.9402 - precision: 0.0769 - recall: 0.3084 - f1_score: 0.1231 - val_loss: 1.4208 - val_accuracy: 0.8734 - val_precision: 0.0770 - val_recall: 0.3082 - val_f1_score: 0.1232\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3104 - accuracy: 0.9330 - precision: 0.0771 - recall: 0.3086 - f1_score: 0.1234 - val_loss: 1.3464 - val_accuracy: 0.8776 - val_precision: 0.0772 - val_recall: 0.3086 - val_f1_score: 0.1235\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.3096 - accuracy: 0.9185 - precision: 0.0774 - recall: 0.3088 - f1_score: 0.1238 - val_loss: 1.2743 - val_accuracy: 0.8734 - val_precision: 0.0775 - val_recall: 0.3090 - val_f1_score: 0.1240\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.4979 - accuracy: 0.9402 - precision: 0.0778 - recall: 0.3096 - f1_score: 0.1244 - val_loss: 1.5253 - val_accuracy: 0.8734 - val_precision: 0.0779 - val_recall: 0.3095 - val_f1_score: 0.1244\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 183ms/step - loss: 0.5117 - accuracy: 0.9384 - precision: 0.0781 - recall: 0.3099 - f1_score: 0.1247 - val_loss: 1.9998 - val_accuracy: 0.8650 - val_precision: 0.0783 - val_recall: 0.3101 - val_f1_score: 0.1250\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 2.4333 - accuracy: 0.9293 - precision: 0.0785 - recall: 0.3104 - f1_score: 0.1253 - val_loss: 2.1724 - val_accuracy: 0.8565 - val_precision: 0.0785 - val_recall: 0.3104 - val_f1_score: 0.1254\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.7121 - accuracy: 0.9239 - precision: 0.0786 - recall: 0.3105 - f1_score: 0.1254 - val_loss: 2.7078 - val_accuracy: 0.8481 - val_precision: 0.0787 - val_recall: 0.3106 - val_f1_score: 0.1256\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.5104 - accuracy: 0.9058 - precision: 0.0787 - recall: 0.3107 - f1_score: 0.1256 - val_loss: 2.6782 - val_accuracy: 0.8650 - val_precision: 0.0788 - val_recall: 0.3105 - val_f1_score: 0.1257\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4233 - accuracy: 0.9076 - precision: 0.0790 - recall: 0.3109 - f1_score: 0.1259 - val_loss: 2.3822 - val_accuracy: 0.8734 - val_precision: 0.0790 - val_recall: 0.3109 - val_f1_score: 0.1260\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.5352 - accuracy: 0.9402 - precision: 0.0792 - recall: 0.3113 - f1_score: 0.1263 - val_loss: 2.3487 - val_accuracy: 0.8650 - val_precision: 0.0794 - val_recall: 0.3116 - val_f1_score: 0.1265\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2820 - accuracy: 0.9366 - precision: 0.0795 - recall: 0.3118 - f1_score: 0.1267 - val_loss: 3.2138 - val_accuracy: 0.8608 - val_precision: 0.0797 - val_recall: 0.3118 - val_f1_score: 0.1269\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.9737 - accuracy: 0.9312 - precision: 0.0799 - recall: 0.3122 - f1_score: 0.1272 - val_loss: 3.1475 - val_accuracy: 0.8734 - val_precision: 0.0800 - val_recall: 0.3120 - val_f1_score: 0.1273\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.9934 - accuracy: 0.9330 - precision: 0.0802 - recall: 0.3123 - f1_score: 0.1276 - val_loss: 3.3799 - val_accuracy: 0.8776 - val_precision: 0.0803 - val_recall: 0.3122 - val_f1_score: 0.1277\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.8159 - accuracy: 0.9293 - precision: 0.0805 - recall: 0.3126 - f1_score: 0.1281 - val_loss: 2.7207 - val_accuracy: 0.8523 - val_precision: 0.0807 - val_recall: 0.3127 - val_f1_score: 0.1282\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.4471 - accuracy: 0.9167 - precision: 0.0809 - recall: 0.3132 - f1_score: 0.1286 - val_loss: 1.9981 - val_accuracy: 0.8608 - val_precision: 0.0811 - val_recall: 0.3133 - val_f1_score: 0.1288\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.4134 - accuracy: 0.9330 - precision: 0.0812 - recall: 0.3134 - f1_score: 0.1290 - val_loss: 2.8378 - val_accuracy: 0.8692 - val_precision: 0.0814 - val_recall: 0.3135 - val_f1_score: 0.1292\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3932 - accuracy: 0.9293 - precision: 0.0816 - recall: 0.3138 - f1_score: 0.1295 - val_loss: 2.3050 - val_accuracy: 0.8523 - val_precision: 0.0817 - val_recall: 0.3139 - val_f1_score: 0.1297\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.7538 - accuracy: 0.9384 - precision: 0.0820 - recall: 0.3144 - f1_score: 0.1301 - val_loss: 2.2003 - val_accuracy: 0.8734 - val_precision: 0.0821 - val_recall: 0.3144 - val_f1_score: 0.1302\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.8962 - accuracy: 0.9420 - precision: 0.0823 - recall: 0.3147 - f1_score: 0.1304 - val_loss: 1.9371 - val_accuracy: 0.8692 - val_precision: 0.0823 - val_recall: 0.3144 - val_f1_score: 0.1305\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.5463 - accuracy: 0.9257 - precision: 0.0825 - recall: 0.3147 - f1_score: 0.1307 - val_loss: 2.2222 - val_accuracy: 0.8692 - val_precision: 0.0826 - val_recall: 0.3148 - val_f1_score: 0.1309\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.8339 - accuracy: 0.9058 - precision: 0.0828 - recall: 0.3151 - f1_score: 0.1311 - val_loss: 1.7785 - val_accuracy: 0.8270 - val_precision: 0.0830 - val_recall: 0.3155 - val_f1_score: 0.1314\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4287 - accuracy: 0.9112 - precision: 0.0832 - recall: 0.3161 - f1_score: 0.1317 - val_loss: 1.9099 - val_accuracy: 0.8608 - val_precision: 0.0834 - val_recall: 0.3163 - val_f1_score: 0.1319\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6940 - accuracy: 0.9312 - precision: 0.0836 - recall: 0.3169 - f1_score: 0.1324 - val_loss: 1.7797 - val_accuracy: 0.8692 - val_precision: 0.0839 - val_recall: 0.3173 - val_f1_score: 0.1327\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2957 - accuracy: 0.9275 - precision: 0.0841 - recall: 0.3179 - f1_score: 0.1331 - val_loss: 1.4181 - val_accuracy: 0.8692 - val_precision: 0.0843 - val_recall: 0.3183 - val_f1_score: 0.1333\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.2999 - accuracy: 0.9420 - precision: 0.0846 - recall: 0.3187 - f1_score: 0.1337 - val_loss: 1.6603 - val_accuracy: 0.8692 - val_precision: 0.0847 - val_recall: 0.3187 - val_f1_score: 0.1339\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2128 - accuracy: 0.9493 - precision: 0.0850 - recall: 0.3194 - f1_score: 0.1343 - val_loss: 1.9366 - val_accuracy: 0.8692 - val_precision: 0.0852 - val_recall: 0.3197 - val_f1_score: 0.1346\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.2582 - accuracy: 0.9493 - precision: 0.0855 - recall: 0.3203 - f1_score: 0.1349 - val_loss: 1.9268 - val_accuracy: 0.8650 - val_precision: 0.0857 - val_recall: 0.3207 - val_f1_score: 0.1352\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2938 - accuracy: 0.9511 - precision: 0.0860 - recall: 0.3212 - f1_score: 0.1356 - val_loss: 1.9984 - val_accuracy: 0.8565 - val_precision: 0.0861 - val_recall: 0.3213 - val_f1_score: 0.1358\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2278 - accuracy: 0.9475 - precision: 0.0864 - recall: 0.3218 - f1_score: 0.1362 - val_loss: 2.3765 - val_accuracy: 0.8776 - val_precision: 0.0866 - val_recall: 0.3221 - val_f1_score: 0.1365\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1572 - accuracy: 0.9583 - precision: 0.0868 - recall: 0.3225 - f1_score: 0.1368 - val_loss: 3.2323 - val_accuracy: 0.8734 - val_precision: 0.0870 - val_recall: 0.3227 - val_f1_score: 0.1370\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.4661 - accuracy: 0.9547 - precision: 0.0872 - recall: 0.3230 - f1_score: 0.1373 - val_loss: 2.4768 - val_accuracy: 0.8776 - val_precision: 0.0874 - val_recall: 0.3231 - val_f1_score: 0.1375\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.2987 - accuracy: 0.9493 - precision: 0.0876 - recall: 0.3236 - f1_score: 0.1379 - val_loss: 1.8702 - val_accuracy: 0.8481 - val_precision: 0.0878 - val_recall: 0.3241 - val_f1_score: 0.1382\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2480 - accuracy: 0.9493 - precision: 0.0880 - recall: 0.3245 - f1_score: 0.1384 - val_loss: 2.1816 - val_accuracy: 0.8523 - val_precision: 0.0882 - val_recall: 0.3248 - val_f1_score: 0.1387\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2718 - accuracy: 0.9420 - precision: 0.0884 - recall: 0.3253 - f1_score: 0.1390 - val_loss: 1.8402 - val_accuracy: 0.8650 - val_precision: 0.0886 - val_recall: 0.3254 - val_f1_score: 0.1393\n",
      "Epoch 260/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2671 - accuracy: 0.9565 - precision: 0.0889 - recall: 0.3260 - f1_score: 0.1397 - val_loss: 2.0935 - val_accuracy: 0.8734 - val_precision: 0.0891 - val_recall: 0.3263 - val_f1_score: 0.1400\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3689 - accuracy: 0.9620 - precision: 0.0894 - recall: 0.3268 - f1_score: 0.1403 - val_loss: 1.7751 - val_accuracy: 0.8565 - val_precision: 0.0896 - val_recall: 0.3271 - val_f1_score: 0.1406\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3184 - accuracy: 0.9312 - precision: 0.0898 - recall: 0.3274 - f1_score: 0.1409 - val_loss: 2.2350 - val_accuracy: 0.8608 - val_precision: 0.0900 - val_recall: 0.3278 - val_f1_score: 0.1413\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2479 - accuracy: 0.9438 - precision: 0.0903 - recall: 0.3282 - f1_score: 0.1416 - val_loss: 2.4849 - val_accuracy: 0.8692 - val_precision: 0.0904 - val_recall: 0.3284 - val_f1_score: 0.1418\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.4922 - accuracy: 0.9565 - precision: 0.0907 - recall: 0.3287 - f1_score: 0.1421 - val_loss: 1.8620 - val_accuracy: 0.8650 - val_precision: 0.0909 - val_recall: 0.3288 - val_f1_score: 0.1424\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2522 - accuracy: 0.9601 - precision: 0.0911 - recall: 0.3294 - f1_score: 0.1428 - val_loss: 1.8970 - val_accuracy: 0.8650 - val_precision: 0.0913 - val_recall: 0.3294 - val_f1_score: 0.1429\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1983 - accuracy: 0.9638 - precision: 0.0916 - recall: 0.3302 - f1_score: 0.1434 - val_loss: 2.3017 - val_accuracy: 0.8608 - val_precision: 0.0919 - val_recall: 0.3307 - val_f1_score: 0.1438\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1863 - accuracy: 0.9620 - precision: 0.0920 - recall: 0.3310 - f1_score: 0.1440 - val_loss: 1.6357 - val_accuracy: 0.8228 - val_precision: 0.0923 - val_recall: 0.3311 - val_f1_score: 0.1443\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1207 - accuracy: 0.9746 - precision: 0.0925 - recall: 0.3315 - f1_score: 0.1446 - val_loss: 1.6117 - val_accuracy: 0.8608 - val_precision: 0.0927 - val_recall: 0.3317 - val_f1_score: 0.1449\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1009 - accuracy: 0.9620 - precision: 0.0930 - recall: 0.3323 - f1_score: 0.1453 - val_loss: 2.3882 - val_accuracy: 0.8650 - val_precision: 0.0933 - val_recall: 0.3328 - val_f1_score: 0.1457\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1293 - accuracy: 0.9764 - precision: 0.0935 - recall: 0.3332 - f1_score: 0.1460 - val_loss: 2.6856 - val_accuracy: 0.8692 - val_precision: 0.0937 - val_recall: 0.3335 - val_f1_score: 0.1463\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1279 - accuracy: 0.9801 - precision: 0.0940 - recall: 0.3341 - f1_score: 0.1467 - val_loss: 3.3406 - val_accuracy: 0.8650 - val_precision: 0.0942 - val_recall: 0.3343 - val_f1_score: 0.1470\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1359 - accuracy: 0.9746 - precision: 0.0945 - recall: 0.3349 - f1_score: 0.1474 - val_loss: 3.0194 - val_accuracy: 0.8565 - val_precision: 0.0948 - val_recall: 0.3353 - val_f1_score: 0.1478\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2967 - accuracy: 0.9420 - precision: 0.0950 - recall: 0.3358 - f1_score: 0.1481 - val_loss: 2.9646 - val_accuracy: 0.8270 - val_precision: 0.0951 - val_recall: 0.3356 - val_f1_score: 0.1482\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3787 - accuracy: 0.9257 - precision: 0.0953 - recall: 0.3356 - f1_score: 0.1484 - val_loss: 2.6046 - val_accuracy: 0.8565 - val_precision: 0.0954 - val_recall: 0.3355 - val_f1_score: 0.1485\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2448 - accuracy: 0.9475 - precision: 0.0955 - recall: 0.3354 - f1_score: 0.1486 - val_loss: 2.7566 - val_accuracy: 0.8565 - val_precision: 0.0956 - val_recall: 0.3352 - val_f1_score: 0.1488\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3472 - accuracy: 0.9438 - precision: 0.0959 - recall: 0.3357 - f1_score: 0.1492 - val_loss: 3.3845 - val_accuracy: 0.8734 - val_precision: 0.0960 - val_recall: 0.3358 - val_f1_score: 0.1494\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1661 - accuracy: 0.9620 - precision: 0.0963 - recall: 0.3363 - f1_score: 0.1498 - val_loss: 3.7547 - val_accuracy: 0.8565 - val_precision: 0.0965 - val_recall: 0.3365 - val_f1_score: 0.1500\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1067 - accuracy: 0.9674 - precision: 0.0968 - recall: 0.3370 - f1_score: 0.1504 - val_loss: 3.9395 - val_accuracy: 0.8270 - val_precision: 0.0970 - val_recall: 0.3371 - val_f1_score: 0.1506\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1579 - accuracy: 0.9656 - precision: 0.0972 - recall: 0.3375 - f1_score: 0.1510 - val_loss: 4.0773 - val_accuracy: 0.8397 - val_precision: 0.0974 - val_recall: 0.3377 - val_f1_score: 0.1512\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1534 - accuracy: 0.9565 - precision: 0.0977 - recall: 0.3382 - f1_score: 0.1516 - val_loss: 6.1224 - val_accuracy: 0.8650 - val_precision: 0.0980 - val_recall: 0.3387 - val_f1_score: 0.1520\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3162 - accuracy: 0.9728 - precision: 0.0982 - recall: 0.3392 - f1_score: 0.1524 - val_loss: 6.4184 - val_accuracy: 0.8481 - val_precision: 0.0985 - val_recall: 0.3394 - val_f1_score: 0.1526\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4378 - accuracy: 0.9420 - precision: 0.0987 - recall: 0.3398 - f1_score: 0.1529 - val_loss: 5.7516 - val_accuracy: 0.8565 - val_precision: 0.0989 - val_recall: 0.3402 - val_f1_score: 0.1533\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3840 - accuracy: 0.9384 - precision: 0.0991 - recall: 0.3405 - f1_score: 0.1536 - val_loss: 5.7434 - val_accuracy: 0.8650 - val_precision: 0.0994 - val_recall: 0.3408 - val_f1_score: 0.1539\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2927 - accuracy: 0.9493 - precision: 0.0997 - recall: 0.3414 - f1_score: 0.1543 - val_loss: 7.4420 - val_accuracy: 0.8608 - val_precision: 0.0999 - val_recall: 0.3417 - val_f1_score: 0.1546\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1720 - accuracy: 0.9692 - precision: 0.1002 - recall: 0.3422 - f1_score: 0.1550 - val_loss: 6.8637 - val_accuracy: 0.8439 - val_precision: 0.1004 - val_recall: 0.3425 - val_f1_score: 0.1553\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1514 - accuracy: 0.9692 - precision: 0.1007 - recall: 0.3430 - f1_score: 0.1557 - val_loss: 6.6495 - val_accuracy: 0.8650 - val_precision: 0.1010 - val_recall: 0.3434 - val_f1_score: 0.1560\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2148 - accuracy: 0.9620 - precision: 0.1012 - recall: 0.3439 - f1_score: 0.1564 - val_loss: 5.0056 - val_accuracy: 0.8523 - val_precision: 0.1014 - val_recall: 0.3441 - val_f1_score: 0.1567\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4545 - accuracy: 0.9511 - precision: 0.1017 - recall: 0.3446 - f1_score: 0.1571 - val_loss: 3.7232 - val_accuracy: 0.8692 - val_precision: 0.1018 - val_recall: 0.3445 - val_f1_score: 0.1572\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2401 - accuracy: 0.9438 - precision: 0.1021 - recall: 0.3448 - f1_score: 0.1575 - val_loss: 3.8339 - val_accuracy: 0.8776 - val_precision: 0.1023 - val_recall: 0.3451 - val_f1_score: 0.1578\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2828 - accuracy: 0.9384 - precision: 0.1026 - recall: 0.3456 - f1_score: 0.1582 - val_loss: 3.5813 - val_accuracy: 0.8481 - val_precision: 0.1027 - val_recall: 0.3455 - val_f1_score: 0.1583\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3042 - accuracy: 0.9511 - precision: 0.1029 - recall: 0.3460 - f1_score: 0.1587 - val_loss: 3.3166 - val_accuracy: 0.8608 - val_precision: 0.1032 - val_recall: 0.3463 - val_f1_score: 0.1590\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1123 - accuracy: 0.9656 - precision: 0.1035 - recall: 0.3471 - f1_score: 0.1595 - val_loss: 4.6456 - val_accuracy: 0.8692 - val_precision: 0.1037 - val_recall: 0.3473 - val_f1_score: 0.1597\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1455 - accuracy: 0.9601 - precision: 0.1041 - recall: 0.3480 - f1_score: 0.1602 - val_loss: 5.4800 - val_accuracy: 0.8776 - val_precision: 0.1043 - val_recall: 0.3482 - val_f1_score: 0.1605\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3103 - accuracy: 0.9511 - precision: 0.1045 - recall: 0.3485 - f1_score: 0.1608 - val_loss: 6.1025 - val_accuracy: 0.8650 - val_precision: 0.1048 - val_recall: 0.3490 - val_f1_score: 0.1612\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3173 - accuracy: 0.9565 - precision: 0.1050 - recall: 0.3494 - f1_score: 0.1615 - val_loss: 14.2801 - val_accuracy: 0.8608 - val_precision: 0.1052 - val_recall: 0.3495 - val_f1_score: 0.1617\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.5087 - accuracy: 0.9330 - precision: 0.1054 - recall: 0.3497 - f1_score: 0.1620 - val_loss: 10.2654 - val_accuracy: 0.8312 - val_precision: 0.1056 - val_recall: 0.3498 - val_f1_score: 0.1622\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4261 - accuracy: 0.9457 - precision: 0.1058 - recall: 0.3500 - f1_score: 0.1624 - val_loss: 8.2361 - val_accuracy: 0.7215 - val_precision: 0.1059 - val_recall: 0.3499 - val_f1_score: 0.1626\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4014 - accuracy: 0.9402 - precision: 0.1062 - recall: 0.3502 - f1_score: 0.1629 - val_loss: 6.5876 - val_accuracy: 0.8439 - val_precision: 0.1063 - val_recall: 0.3504 - val_f1_score: 0.1632\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2624 - accuracy: 0.9656 - precision: 0.1065 - recall: 0.3505 - f1_score: 0.1634 - val_loss: 6.7410 - val_accuracy: 0.8650 - val_precision: 0.1067 - val_recall: 0.3507 - val_f1_score: 0.1636\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1814 - accuracy: 0.9656 - precision: 0.1070 - recall: 0.3511 - f1_score: 0.1640 - val_loss: 7.0004 - val_accuracy: 0.8734 - val_precision: 0.1072 - val_recall: 0.3514 - val_f1_score: 0.1643\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2161 - accuracy: 0.9692 - precision: 0.1075 - recall: 0.3519 - f1_score: 0.1647 - val_loss: 7.7488 - val_accuracy: 0.8228 - val_precision: 0.1077 - val_recall: 0.3522 - val_f1_score: 0.1650\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1431 - accuracy: 0.9710 - precision: 0.1080 - recall: 0.3528 - f1_score: 0.1654 - val_loss: 8.8413 - val_accuracy: 0.8481 - val_precision: 0.1083 - val_recall: 0.3531 - val_f1_score: 0.1657\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1489 - accuracy: 0.9801 - precision: 0.1086 - recall: 0.3538 - f1_score: 0.1662 - val_loss: 8.3577 - val_accuracy: 0.8734 - val_precision: 0.1089 - val_recall: 0.3542 - val_f1_score: 0.1666\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1776 - accuracy: 0.9674 - precision: 0.1091 - recall: 0.3546 - f1_score: 0.1669 - val_loss: 7.7868 - val_accuracy: 0.8608 - val_precision: 0.1094 - val_recall: 0.3549 - val_f1_score: 0.1672\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2289 - accuracy: 0.9692 - precision: 0.1097 - recall: 0.3555 - f1_score: 0.1677 - val_loss: 7.6918 - val_accuracy: 0.8481 - val_precision: 0.1099 - val_recall: 0.3557 - val_f1_score: 0.1679\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1487 - accuracy: 0.9692 - precision: 0.1102 - recall: 0.3562 - f1_score: 0.1683 - val_loss: 8.0493 - val_accuracy: 0.8692 - val_precision: 0.1104 - val_recall: 0.3566 - val_f1_score: 0.1687\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0690 - accuracy: 0.9873 - precision: 0.1108 - recall: 0.3573 - f1_score: 0.1691 - val_loss: 7.5925 - val_accuracy: 0.8650 - val_precision: 0.1111 - val_recall: 0.3578 - val_f1_score: 0.1695\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1577 - accuracy: 0.9746 - precision: 0.1113 - recall: 0.3582 - f1_score: 0.1699 - val_loss: 8.3299 - val_accuracy: 0.8608 - val_precision: 0.1116 - val_recall: 0.3586 - val_f1_score: 0.1702\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0470 - accuracy: 0.9855 - precision: 0.1118 - recall: 0.3591 - f1_score: 0.1706 - val_loss: 8.5804 - val_accuracy: 0.8481 - val_precision: 0.1121 - val_recall: 0.3594 - val_f1_score: 0.1709\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0546 - accuracy: 0.9783 - precision: 0.1125 - recall: 0.3601 - f1_score: 0.1714 - val_loss: 8.5807 - val_accuracy: 0.8228 - val_precision: 0.1127 - val_recall: 0.3604 - val_f1_score: 0.1717\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0677 - accuracy: 0.9819 - precision: 0.1129 - recall: 0.3608 - f1_score: 0.1720 - val_loss: 8.6924 - val_accuracy: 0.8734 - val_precision: 0.1132 - val_recall: 0.3612 - val_f1_score: 0.1724\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1494 - accuracy: 0.9656 - precision: 0.1134 - recall: 0.3616 - f1_score: 0.1727 - val_loss: 8.1170 - val_accuracy: 0.7932 - val_precision: 0.1137 - val_recall: 0.3620 - val_f1_score: 0.1730\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1801 - accuracy: 0.9801 - precision: 0.1140 - recall: 0.3625 - f1_score: 0.1734 - val_loss: 8.7571 - val_accuracy: 0.8017 - val_precision: 0.1142 - val_recall: 0.3627 - val_f1_score: 0.1737\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0809 - accuracy: 0.9873 - precision: 0.1144 - recall: 0.3630 - f1_score: 0.1739 - val_loss: 8.7169 - val_accuracy: 0.8650 - val_precision: 0.1147 - val_recall: 0.3635 - val_f1_score: 0.1744\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.3545 - accuracy: 0.9819 - precision: 0.1150 - recall: 0.3640 - f1_score: 0.1748 - val_loss: 8.4540 - val_accuracy: 0.8650 - val_precision: 0.1151 - val_recall: 0.3640 - val_f1_score: 0.1749\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.4924 - accuracy: 0.9529 - precision: 0.1154 - recall: 0.3645 - f1_score: 0.1753 - val_loss: 13.4278 - val_accuracy: 0.8439 - val_precision: 0.1156 - val_recall: 0.3647 - val_f1_score: 0.1755\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.4570 - accuracy: 0.9638 - precision: 0.1158 - recall: 0.3650 - f1_score: 0.1758 - val_loss: 8.5425 - val_accuracy: 0.8650 - val_precision: 0.1160 - val_recall: 0.3650 - val_f1_score: 0.1760\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2371 - accuracy: 0.9656 - precision: 0.1162 - recall: 0.3652 - f1_score: 0.1763 - val_loss: 7.8887 - val_accuracy: 0.8523 - val_precision: 0.1163 - val_recall: 0.3651 - val_f1_score: 0.1764\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2431 - accuracy: 0.9493 - precision: 0.1165 - recall: 0.3654 - f1_score: 0.1766 - val_loss: 7.1883 - val_accuracy: 0.8608 - val_precision: 0.1167 - val_recall: 0.3656 - val_f1_score: 0.1769\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3502 - accuracy: 0.9475 - precision: 0.1169 - recall: 0.3658 - f1_score: 0.1771 - val_loss: 5.5936 - val_accuracy: 0.8650 - val_precision: 0.1170 - val_recall: 0.3659 - val_f1_score: 0.1774\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0945 - accuracy: 0.9783 - precision: 0.1173 - recall: 0.3662 - f1_score: 0.1777 - val_loss: 5.2646 - val_accuracy: 0.8692 - val_precision: 0.1175 - val_recall: 0.3664 - val_f1_score: 0.1779\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1120 - accuracy: 0.9764 - precision: 0.1178 - recall: 0.3668 - f1_score: 0.1783 - val_loss: 5.1321 - val_accuracy: 0.8734 - val_precision: 0.1180 - val_recall: 0.3670 - val_f1_score: 0.1785\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0732 - accuracy: 0.9891 - precision: 0.1183 - recall: 0.3674 - f1_score: 0.1789 - val_loss: 5.5290 - val_accuracy: 0.8819 - val_precision: 0.1185 - val_recall: 0.3677 - val_f1_score: 0.1792\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1707 - accuracy: 0.9837 - precision: 0.1188 - recall: 0.3681 - f1_score: 0.1796 - val_loss: 5.8688 - val_accuracy: 0.8945 - val_precision: 0.1190 - val_recall: 0.3683 - val_f1_score: 0.1799\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.0761 - accuracy: 0.9855 - precision: 0.1193 - recall: 0.3689 - f1_score: 0.1803 - val_loss: 5.2182 - val_accuracy: 0.8734 - val_precision: 0.1195 - val_recall: 0.3691 - val_f1_score: 0.1806\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1363 - accuracy: 0.9746 - precision: 0.1198 - recall: 0.3697 - f1_score: 0.1810 - val_loss: 6.7532 - val_accuracy: 0.8945 - val_precision: 0.1201 - val_recall: 0.3700 - val_f1_score: 0.1813\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.0570 - accuracy: 0.9837 - precision: 0.1203 - recall: 0.3705 - f1_score: 0.1817 - val_loss: 6.8248 - val_accuracy: 0.8734 - val_precision: 0.1206 - val_recall: 0.3707 - val_f1_score: 0.1820\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.0492 - accuracy: 0.9855 - precision: 0.1209 - recall: 0.3713 - f1_score: 0.1824 - val_loss: 6.9470 - val_accuracy: 0.8734 - val_precision: 0.1211 - val_recall: 0.3716 - val_f1_score: 0.1827\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.1024 - accuracy: 0.9837 - precision: 0.1214 - recall: 0.3721 - f1_score: 0.1831 - val_loss: 6.3468 - val_accuracy: 0.8650 - val_precision: 0.1216 - val_recall: 0.3723 - val_f1_score: 0.1834\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0475 - accuracy: 0.9819 - precision: 0.1219 - recall: 0.3728 - f1_score: 0.1837 - val_loss: 6.3554 - val_accuracy: 0.8692 - val_precision: 0.1222 - val_recall: 0.3733 - val_f1_score: 0.1841\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1170 - accuracy: 0.9801 - precision: 0.1226 - recall: 0.3739 - f1_score: 0.1846 - val_loss: 7.9916 - val_accuracy: 0.8819 - val_precision: 0.1228 - val_recall: 0.3741 - val_f1_score: 0.1849\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1611 - accuracy: 0.9692 - precision: 0.1230 - recall: 0.3744 - f1_score: 0.1852 - val_loss: 7.2466 - val_accuracy: 0.8861 - val_precision: 0.1232 - val_recall: 0.3746 - val_f1_score: 0.1855\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.1865 - accuracy: 0.9674 - precision: 0.1236 - recall: 0.3752 - f1_score: 0.1859 - val_loss: 8.3961 - val_accuracy: 0.8776 - val_precision: 0.1238 - val_recall: 0.3754 - val_f1_score: 0.1862\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.1064 - accuracy: 0.9764 - precision: 0.1240 - recall: 0.3758 - f1_score: 0.1865 - val_loss: 7.6534 - val_accuracy: 0.8819 - val_precision: 0.1243 - val_recall: 0.3761 - val_f1_score: 0.1868\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.0719 - accuracy: 0.9837 - precision: 0.1246 - recall: 0.3765 - f1_score: 0.1872 - val_loss: 7.4089 - val_accuracy: 0.8903 - val_precision: 0.1248 - val_recall: 0.3768 - val_f1_score: 0.1875\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1054 - accuracy: 0.9764 - precision: 0.1250 - recall: 0.3773 - f1_score: 0.1878 - val_loss: 6.9204 - val_accuracy: 0.8439 - val_precision: 0.1253 - val_recall: 0.3777 - val_f1_score: 0.1882\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0474 - accuracy: 0.9837 - precision: 0.1256 - recall: 0.3780 - f1_score: 0.1885 - val_loss: 7.0615 - val_accuracy: 0.8734 - val_precision: 0.1257 - val_recall: 0.3781 - val_f1_score: 0.1887\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0213 - accuracy: 0.9891 - precision: 0.1261 - recall: 0.3787 - f1_score: 0.1892 - val_loss: 6.8608 - val_accuracy: 0.8692 - val_precision: 0.1263 - val_recall: 0.3790 - val_f1_score: 0.1895\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0162 - accuracy: 0.9909 - precision: 0.1265 - recall: 0.3794 - f1_score: 0.1898 - val_loss: 7.1748 - val_accuracy: 0.8861 - val_precision: 0.1269 - val_recall: 0.3799 - val_f1_score: 0.1902\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0107 - accuracy: 0.9909 - precision: 0.1271 - recall: 0.3803 - f1_score: 0.1905 - val_loss: 7.4330 - val_accuracy: 0.8776 - val_precision: 0.1274 - val_recall: 0.3806 - val_f1_score: 0.1909\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0428 - accuracy: 0.9909 - precision: 0.1277 - recall: 0.3811 - f1_score: 0.1913 - val_loss: 7.2605 - val_accuracy: 0.8776 - val_precision: 0.1279 - val_recall: 0.3815 - val_f1_score: 0.1916\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1608 - accuracy: 0.9891 - precision: 0.1282 - recall: 0.3819 - f1_score: 0.1919 - val_loss: 6.5538 - val_accuracy: 0.8523 - val_precision: 0.1285 - val_recall: 0.3825 - val_f1_score: 0.1924\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0366 - accuracy: 0.9891 - precision: 0.1287 - recall: 0.3829 - f1_score: 0.1927 - val_loss: 7.3022 - val_accuracy: 0.8861 - val_precision: 0.1290 - val_recall: 0.3832 - val_f1_score: 0.1930\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.0605 - accuracy: 0.9891 - precision: 0.1294 - recall: 0.3839 - f1_score: 0.1935 - val_loss: 6.9858 - val_accuracy: 0.8692 - val_precision: 0.1296 - val_recall: 0.3841 - val_f1_score: 0.1938\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.0052 - accuracy: 0.9964 - precision: 0.1299 - recall: 0.3848 - f1_score: 0.1943 - val_loss: 7.1815 - val_accuracy: 0.8692 - val_precision: 0.1301 - val_recall: 0.3850 - val_f1_score: 0.1945\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0112 - accuracy: 0.9964 - precision: 0.1304 - recall: 0.3855 - f1_score: 0.1949 - val_loss: 7.3634 - val_accuracy: 0.8776 - val_precision: 0.1307 - val_recall: 0.3858 - val_f1_score: 0.1953\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0180 - accuracy: 0.9946 - precision: 0.1310 - recall: 0.3863 - f1_score: 0.1956 - val_loss: 7.4688 - val_accuracy: 0.8776 - val_precision: 0.1312 - val_recall: 0.3867 - val_f1_score: 0.1960\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0727 - accuracy: 0.9946 - precision: 0.1316 - recall: 0.3872 - f1_score: 0.1964 - val_loss: 7.8494 - val_accuracy: 0.8734 - val_precision: 0.1318 - val_recall: 0.3876 - val_f1_score: 0.1968\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0903 - accuracy: 0.9891 - precision: 0.1322 - recall: 0.3883 - f1_score: 0.1972 - val_loss: 8.4373 - val_accuracy: 0.8734 - val_precision: 0.1324 - val_recall: 0.3885 - val_f1_score: 0.1975\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0513 - accuracy: 0.9928 - precision: 0.1327 - recall: 0.3889 - f1_score: 0.1979 - val_loss: 7.9830 - val_accuracy: 0.8650 - val_precision: 0.1329 - val_recall: 0.3892 - val_f1_score: 0.1982\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.4296 - accuracy: 0.9928 - precision: 0.1333 - recall: 0.3899 - f1_score: 0.1986 - val_loss: 6.9674 - val_accuracy: 0.8397 - val_precision: 0.1335 - val_recall: 0.3901 - val_f1_score: 0.1989\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.1334 - accuracy: 0.9909 - precision: 0.1338 - recall: 0.3906 - f1_score: 0.1993 - val_loss: 6.2816 - val_accuracy: 0.8565 - val_precision: 0.1340 - val_recall: 0.3911 - val_f1_score: 0.1996\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.3008 - accuracy: 0.9837 - precision: 0.1342 - recall: 0.3914 - f1_score: 0.1999 - val_loss: 6.7877 - val_accuracy: 0.8565 - val_precision: 0.1345 - val_recall: 0.3916 - val_f1_score: 0.2002\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.1854 - accuracy: 0.9656 - precision: 0.1348 - recall: 0.3921 - f1_score: 0.2006 - val_loss: 6.9321 - val_accuracy: 0.8439 - val_precision: 0.1350 - val_recall: 0.3922 - val_f1_score: 0.2008\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.6212 - accuracy: 0.9692 - precision: 0.1352 - recall: 0.3926 - f1_score: 0.2011 - val_loss: 7.6614 - val_accuracy: 0.8565 - val_precision: 0.1354 - val_recall: 0.3926 - val_f1_score: 0.2013\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0755 - accuracy: 0.9891 - precision: 0.1357 - recall: 0.3931 - f1_score: 0.2017 - val_loss: 10.5096 - val_accuracy: 0.8565 - val_precision: 0.1359 - val_recall: 0.3933 - val_f1_score: 0.2020\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1482 - accuracy: 0.9819 - precision: 0.1362 - recall: 0.3938 - f1_score: 0.2024 - val_loss: 10.4130 - val_accuracy: 0.8692 - val_precision: 0.1365 - val_recall: 0.3942 - val_f1_score: 0.2028\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1658 - accuracy: 0.9891 - precision: 0.1368 - recall: 0.3946 - f1_score: 0.2031 - val_loss: 11.5006 - val_accuracy: 0.8734 - val_precision: 0.1370 - val_recall: 0.3950 - val_f1_score: 0.2035\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0497 - accuracy: 0.9891 - precision: 0.1374 - recall: 0.3956 - f1_score: 0.2039 - val_loss: 12.5674 - val_accuracy: 0.8734 - val_precision: 0.1376 - val_recall: 0.3959 - val_f1_score: 0.2042\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0283 - accuracy: 0.9964 - precision: 0.1379 - recall: 0.3964 - f1_score: 0.2046 - val_loss: 12.0337 - val_accuracy: 0.8819 - val_precision: 0.1382 - val_recall: 0.3968 - val_f1_score: 0.2050\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0697 - accuracy: 0.9891 - precision: 0.1384 - recall: 0.3972 - f1_score: 0.2053 - val_loss: 10.5933 - val_accuracy: 0.8692 - val_precision: 0.1388 - val_recall: 0.3976 - val_f1_score: 0.2057\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0453 - accuracy: 0.9873 - precision: 0.1391 - recall: 0.3981 - f1_score: 0.2061 - val_loss: 12.7386 - val_accuracy: 0.8650 - val_precision: 0.1393 - val_recall: 0.3984 - val_f1_score: 0.2064\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1521 - accuracy: 0.9891 - precision: 0.1396 - recall: 0.3989 - f1_score: 0.2068 - val_loss: 10.8189 - val_accuracy: 0.8439 - val_precision: 0.1399 - val_recall: 0.3993 - val_f1_score: 0.2072\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1797 - accuracy: 0.9692 - precision: 0.1402 - recall: 0.3997 - f1_score: 0.2076 - val_loss: 8.8537 - val_accuracy: 0.8608 - val_precision: 0.1404 - val_recall: 0.3998 - val_f1_score: 0.2078\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1607 - accuracy: 0.9801 - precision: 0.1406 - recall: 0.4002 - f1_score: 0.2081 - val_loss: 9.8595 - val_accuracy: 0.8523 - val_precision: 0.1409 - val_recall: 0.4006 - val_f1_score: 0.2085\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.1115 - accuracy: 0.9855 - precision: 0.1412 - recall: 0.4010 - f1_score: 0.2089 - val_loss: 8.3020 - val_accuracy: 0.8354 - val_precision: 0.1415 - val_recall: 0.4014 - val_f1_score: 0.2092\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.1704 - accuracy: 0.9873 - precision: 0.1418 - recall: 0.4018 - f1_score: 0.2096 - val_loss: 8.7598 - val_accuracy: 0.8776 - val_precision: 0.1420 - val_recall: 0.4021 - val_f1_score: 0.2099\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1366 - accuracy: 0.9692 - precision: 0.1423 - recall: 0.4026 - f1_score: 0.2103 - val_loss: 18.1338 - val_accuracy: 0.8439 - val_precision: 0.1425 - val_recall: 0.4027 - val_f1_score: 0.2105\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2207 - accuracy: 0.9710 - precision: 0.1427 - recall: 0.4030 - f1_score: 0.2108 - val_loss: 17.0288 - val_accuracy: 0.8354 - val_precision: 0.1429 - val_recall: 0.4031 - val_f1_score: 0.2110\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.3263 - accuracy: 0.9656 - precision: 0.1431 - recall: 0.4034 - f1_score: 0.2112 - val_loss: 15.2046 - val_accuracy: 0.8439 - val_precision: 0.1433 - val_recall: 0.4036 - val_f1_score: 0.2115\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1421 - accuracy: 0.9801 - precision: 0.1436 - recall: 0.4040 - f1_score: 0.2119 - val_loss: 13.3234 - val_accuracy: 0.8650 - val_precision: 0.1439 - val_recall: 0.4043 - val_f1_score: 0.2122\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0884 - accuracy: 0.9873 - precision: 0.1441 - recall: 0.4047 - f1_score: 0.2126 - val_loss: 11.9790 - val_accuracy: 0.8481 - val_precision: 0.1443 - val_recall: 0.4048 - val_f1_score: 0.2128\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1498 - accuracy: 0.9801 - precision: 0.1446 - recall: 0.4052 - f1_score: 0.2131 - val_loss: 21.4175 - val_accuracy: 0.8650 - val_precision: 0.1448 - val_recall: 0.4054 - val_f1_score: 0.2134\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0095 - accuracy: 0.9982 - precision: 0.1450 - recall: 0.4057 - f1_score: 0.2137 - val_loss: 23.6791 - val_accuracy: 0.8734 - val_precision: 0.1453 - val_recall: 0.4060 - val_f1_score: 0.2140\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0285 - accuracy: 0.9946 - precision: 0.1456 - recall: 0.4063 - f1_score: 0.2143 - val_loss: 25.6793 - val_accuracy: 0.8776 - val_precision: 0.1458 - val_recall: 0.4065 - val_f1_score: 0.2146\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.0252 - accuracy: 0.9909 - precision: 0.1461 - recall: 0.4070 - f1_score: 0.2151 - val_loss: 25.9799 - val_accuracy: 0.8692 - val_precision: 0.1463 - val_recall: 0.4071 - val_f1_score: 0.2153\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.5084 - accuracy: 0.9801 - precision: 0.1466 - recall: 0.4076 - f1_score: 0.2157 - val_loss: 23.8380 - val_accuracy: 0.8776 - val_precision: 0.1468 - val_recall: 0.4076 - val_f1_score: 0.2159\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.3639 - accuracy: 0.9728 - precision: 0.1470 - recall: 0.4079 - f1_score: 0.2161 - val_loss: 18.0256 - val_accuracy: 0.8565 - val_precision: 0.1473 - val_recall: 0.4081 - val_f1_score: 0.2164\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.6004 - accuracy: 0.9692 - precision: 0.1475 - recall: 0.4085 - f1_score: 0.2167 - val_loss: 15.2795 - val_accuracy: 0.8481 - val_precision: 0.1477 - val_recall: 0.4085 - val_f1_score: 0.2170\n",
      "Epoch 380/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2038 - accuracy: 0.9801 - precision: 0.1479 - recall: 0.4088 - f1_score: 0.2172 - val_loss: 14.3493 - val_accuracy: 0.8523 - val_precision: 0.1482 - val_recall: 0.4091 - val_f1_score: 0.2176\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3767 - accuracy: 0.9819 - precision: 0.1485 - recall: 0.4096 - f1_score: 0.2180 - val_loss: 15.5243 - val_accuracy: 0.8734 - val_precision: 0.1487 - val_recall: 0.4098 - val_f1_score: 0.2182\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6243 - accuracy: 0.9783 - precision: 0.1490 - recall: 0.4103 - f1_score: 0.2186 - val_loss: 9.6746 - val_accuracy: 0.8354 - val_precision: 0.1492 - val_recall: 0.4104 - val_f1_score: 0.2189\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0610 - accuracy: 0.9909 - precision: 0.1495 - recall: 0.4109 - f1_score: 0.2192 - val_loss: 13.0473 - val_accuracy: 0.8608 - val_precision: 0.1497 - val_recall: 0.4111 - val_f1_score: 0.2195\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3873 - accuracy: 0.9891 - precision: 0.1499 - recall: 0.4114 - f1_score: 0.2198 - val_loss: 15.0100 - val_accuracy: 0.8734 - val_precision: 0.1501 - val_recall: 0.4116 - val_f1_score: 0.2200\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.2083 - accuracy: 0.9819 - precision: 0.1503 - recall: 0.4115 - f1_score: 0.2202 - val_loss: 15.4338 - val_accuracy: 0.8650 - val_precision: 0.1504 - val_recall: 0.4115 - val_f1_score: 0.2203\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0923 - accuracy: 0.9873 - precision: 0.1506 - recall: 0.4119 - f1_score: 0.2206 - val_loss: 21.5632 - val_accuracy: 0.8650 - val_precision: 0.1509 - val_recall: 0.4120 - val_f1_score: 0.2208\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0832 - accuracy: 0.9891 - precision: 0.1511 - recall: 0.4123 - f1_score: 0.2212 - val_loss: 13.6663 - val_accuracy: 0.8565 - val_precision: 0.1513 - val_recall: 0.4126 - val_f1_score: 0.2215\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.8135 - accuracy: 0.9855 - precision: 0.1516 - recall: 0.4129 - f1_score: 0.2218 - val_loss: 13.5489 - val_accuracy: 0.8861 - val_precision: 0.1518 - val_recall: 0.4131 - val_f1_score: 0.2221\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2449 - accuracy: 0.9710 - precision: 0.1521 - recall: 0.4135 - f1_score: 0.2224 - val_loss: 16.0142 - val_accuracy: 0.8776 - val_precision: 0.1523 - val_recall: 0.4135 - val_f1_score: 0.2226\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3621 - accuracy: 0.9692 - precision: 0.1525 - recall: 0.4138 - f1_score: 0.2229 - val_loss: 11.9338 - val_accuracy: 0.8692 - val_precision: 0.1527 - val_recall: 0.4140 - val_f1_score: 0.2231\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.7761 - accuracy: 0.9728 - precision: 0.1529 - recall: 0.4143 - f1_score: 0.2234 - val_loss: 13.9199 - val_accuracy: 0.8692 - val_precision: 0.1532 - val_recall: 0.4145 - val_f1_score: 0.2237\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.8379 - accuracy: 0.9565 - precision: 0.1533 - recall: 0.4145 - f1_score: 0.2239 - val_loss: 12.3886 - val_accuracy: 0.8397 - val_precision: 0.1536 - val_recall: 0.4146 - val_f1_score: 0.2241\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6155 - accuracy: 0.9620 - precision: 0.1538 - recall: 0.4150 - f1_score: 0.2245 - val_loss: 13.7313 - val_accuracy: 0.8650 - val_precision: 0.1540 - val_recall: 0.4152 - val_f1_score: 0.2247\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.5543 - accuracy: 0.9692 - precision: 0.1543 - recall: 0.4156 - f1_score: 0.2251 - val_loss: 9.6259 - val_accuracy: 0.8354 - val_precision: 0.1545 - val_recall: 0.4157 - val_f1_score: 0.2253\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4184 - accuracy: 0.9674 - precision: 0.1547 - recall: 0.4160 - f1_score: 0.2256 - val_loss: 9.7459 - val_accuracy: 0.8523 - val_precision: 0.1549 - val_recall: 0.4162 - val_f1_score: 0.2258\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4936 - accuracy: 0.9746 - precision: 0.1553 - recall: 0.4166 - f1_score: 0.2262 - val_loss: 13.8639 - val_accuracy: 0.8270 - val_precision: 0.1555 - val_recall: 0.4168 - val_f1_score: 0.2265\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6136 - accuracy: 0.9511 - precision: 0.1557 - recall: 0.4172 - f1_score: 0.2268 - val_loss: 11.2752 - val_accuracy: 0.8650 - val_precision: 0.1559 - val_recall: 0.4173 - val_f1_score: 0.2270\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1607 - accuracy: 0.9873 - precision: 0.1562 - recall: 0.4177 - f1_score: 0.2274 - val_loss: 16.7435 - val_accuracy: 0.8692 - val_precision: 0.1564 - val_recall: 0.4178 - val_f1_score: 0.2276\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4499 - accuracy: 0.9819 - precision: 0.1566 - recall: 0.4178 - f1_score: 0.2278 - val_loss: 10.8274 - val_accuracy: 0.8017 - val_precision: 0.1567 - val_recall: 0.4179 - val_f1_score: 0.2279\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.9858 - accuracy: 0.9783 - precision: 0.1570 - recall: 0.4184 - f1_score: 0.2283 - val_loss: 10.9754 - val_accuracy: 0.8861 - val_precision: 0.1572 - val_recall: 0.4184 - val_f1_score: 0.2285\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0224 - accuracy: 0.9529 - precision: 0.1574 - recall: 0.4188 - f1_score: 0.2288 - val_loss: 20.4222 - val_accuracy: 0.8481 - val_precision: 0.1576 - val_recall: 0.4189 - val_f1_score: 0.2290\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6879 - accuracy: 0.9511 - precision: 0.1578 - recall: 0.4192 - f1_score: 0.2293 - val_loss: 15.1128 - val_accuracy: 0.8692 - val_precision: 0.1579 - val_recall: 0.4191 - val_f1_score: 0.2294\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3340 - accuracy: 0.9565 - precision: 0.1581 - recall: 0.4194 - f1_score: 0.2297 - val_loss: 15.2700 - val_accuracy: 0.8776 - val_precision: 0.1583 - val_recall: 0.4195 - val_f1_score: 0.2299\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4640 - accuracy: 0.9819 - precision: 0.1586 - recall: 0.4197 - f1_score: 0.2302 - val_loss: 13.5946 - val_accuracy: 0.8186 - val_precision: 0.1587 - val_recall: 0.4199 - val_f1_score: 0.2304\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2489 - accuracy: 0.9728 - precision: 0.1590 - recall: 0.4203 - f1_score: 0.2307 - val_loss: 14.5906 - val_accuracy: 0.8903 - val_precision: 0.1592 - val_recall: 0.4205 - val_f1_score: 0.2310\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0416 - accuracy: 0.9909 - precision: 0.1595 - recall: 0.4209 - f1_score: 0.2313 - val_loss: 15.9671 - val_accuracy: 0.8903 - val_precision: 0.1597 - val_recall: 0.4210 - val_f1_score: 0.2316\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1066 - accuracy: 0.9928 - precision: 0.1600 - recall: 0.4214 - f1_score: 0.2319 - val_loss: 14.7510 - val_accuracy: 0.8861 - val_precision: 0.1601 - val_recall: 0.4214 - val_f1_score: 0.2321\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.8161 - accuracy: 0.9891 - precision: 0.1604 - recall: 0.4218 - f1_score: 0.2325 - val_loss: 16.9008 - val_accuracy: 0.8819 - val_precision: 0.1606 - val_recall: 0.4220 - val_f1_score: 0.2327\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1171 - accuracy: 0.9909 - precision: 0.1608 - recall: 0.4223 - f1_score: 0.2330 - val_loss: 19.4379 - val_accuracy: 0.8439 - val_precision: 0.1611 - val_recall: 0.4225 - val_f1_score: 0.2333\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2354 - accuracy: 0.9819 - precision: 0.1613 - recall: 0.4229 - f1_score: 0.2336 - val_loss: 18.1368 - val_accuracy: 0.5359 - val_precision: 0.1615 - val_recall: 0.4231 - val_f1_score: 0.2338\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1429 - accuracy: 0.9891 - precision: 0.1619 - recall: 0.4236 - f1_score: 0.2342 - val_loss: 14.2239 - val_accuracy: 0.7722 - val_precision: 0.1620 - val_recall: 0.4236 - val_f1_score: 0.2344\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.3340 - accuracy: 0.9819 - precision: 0.1623 - recall: 0.4240 - f1_score: 0.2347 - val_loss: 12.5130 - val_accuracy: 0.8017 - val_precision: 0.1625 - val_recall: 0.4241 - val_f1_score: 0.2350\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1799 - accuracy: 0.9873 - precision: 0.1628 - recall: 0.4244 - f1_score: 0.2353 - val_loss: 12.6024 - val_accuracy: 0.8565 - val_precision: 0.1630 - val_recall: 0.4247 - val_f1_score: 0.2356\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1480 - accuracy: 0.9946 - precision: 0.1633 - recall: 0.4251 - f1_score: 0.2359 - val_loss: 15.8365 - val_accuracy: 0.8734 - val_precision: 0.1635 - val_recall: 0.4253 - val_f1_score: 0.2362\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.5602 - accuracy: 0.9692 - precision: 0.1637 - recall: 0.4254 - f1_score: 0.2364 - val_loss: 12.4919 - val_accuracy: 0.7300 - val_precision: 0.1638 - val_recall: 0.4253 - val_f1_score: 0.2365\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.6780 - accuracy: 0.9801 - precision: 0.1642 - recall: 0.4258 - f1_score: 0.2370 - val_loss: 13.6703 - val_accuracy: 0.8692 - val_precision: 0.1643 - val_recall: 0.4258 - val_f1_score: 0.2371\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1485 - accuracy: 0.9873 - precision: 0.1646 - recall: 0.4262 - f1_score: 0.2375 - val_loss: 8.3814 - val_accuracy: 0.7764 - val_precision: 0.1648 - val_recall: 0.4262 - val_f1_score: 0.2376\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.3448 - accuracy: 0.9692 - precision: 0.1650 - recall: 0.4266 - f1_score: 0.2379 - val_loss: 10.1833 - val_accuracy: 0.8565 - val_precision: 0.1652 - val_recall: 0.4267 - val_f1_score: 0.2381\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.1756 - accuracy: 0.9801 - precision: 0.1654 - recall: 0.4270 - f1_score: 0.2384 - val_loss: 11.3285 - val_accuracy: 0.8650 - val_precision: 0.1656 - val_recall: 0.4271 - val_f1_score: 0.2387\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.3208 - accuracy: 0.9801 - precision: 0.1658 - recall: 0.4273 - f1_score: 0.2389 - val_loss: 9.1104 - val_accuracy: 0.8608 - val_precision: 0.1660 - val_recall: 0.4275 - val_f1_score: 0.2392\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0204 - accuracy: 0.9964 - precision: 0.1663 - recall: 0.4279 - f1_score: 0.2395 - val_loss: 9.8997 - val_accuracy: 0.8819 - val_precision: 0.1665 - val_recall: 0.4279 - val_f1_score: 0.2397\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1651 - accuracy: 0.9873 - precision: 0.1668 - recall: 0.4283 - f1_score: 0.2401 - val_loss: 9.7786 - val_accuracy: 0.8776 - val_precision: 0.1670 - val_recall: 0.4284 - val_f1_score: 0.2403\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1432 - accuracy: 0.9819 - precision: 0.1672 - recall: 0.4287 - f1_score: 0.2406 - val_loss: 11.3545 - val_accuracy: 0.8861 - val_precision: 0.1674 - val_recall: 0.4289 - val_f1_score: 0.2408\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0461 - accuracy: 0.9928 - precision: 0.1677 - recall: 0.4292 - f1_score: 0.2412 - val_loss: 12.3727 - val_accuracy: 0.8650 - val_precision: 0.1679 - val_recall: 0.4295 - val_f1_score: 0.2415\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0959 - accuracy: 0.9928 - precision: 0.1682 - recall: 0.4298 - f1_score: 0.2418 - val_loss: 12.4365 - val_accuracy: 0.8819 - val_precision: 0.1684 - val_recall: 0.4300 - val_f1_score: 0.2421\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.1834 - accuracy: 0.9946 - precision: 0.1687 - recall: 0.4303 - f1_score: 0.2424 - val_loss: 12.0490 - val_accuracy: 0.8734 - val_precision: 0.1689 - val_recall: 0.4305 - val_f1_score: 0.2426\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.1300 - accuracy: 0.9946 - precision: 0.1692 - recall: 0.4308 - f1_score: 0.2430 - val_loss: 14.8574 - val_accuracy: 0.8776 - val_precision: 0.1694 - val_recall: 0.4311 - val_f1_score: 0.2433\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.1065 - accuracy: 0.9891 - precision: 0.1697 - recall: 0.4313 - f1_score: 0.2435 - val_loss: 16.6834 - val_accuracy: 0.8819 - val_precision: 0.1699 - val_recall: 0.4315 - val_f1_score: 0.2438\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0692 - accuracy: 0.9946 - precision: 0.1702 - recall: 0.4320 - f1_score: 0.2442 - val_loss: 13.8338 - val_accuracy: 0.8692 - val_precision: 0.1704 - val_recall: 0.4321 - val_f1_score: 0.2445\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.1114 - accuracy: 0.9946 - precision: 0.1707 - recall: 0.4325 - f1_score: 0.2448 - val_loss: 13.7239 - val_accuracy: 0.8903 - val_precision: 0.1710 - val_recall: 0.4327 - val_f1_score: 0.2451\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 5.1636e-04 - accuracy: 1.0000 - precision: 0.1713 - recall: 0.4332 - f1_score: 0.2456 - val_loss: 14.2314 - val_accuracy: 0.8903 - val_precision: 0.1715 - val_recall: 0.4333 - val_f1_score: 0.2457\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0126 - accuracy: 0.9964 - precision: 0.1718 - recall: 0.4337 - f1_score: 0.2461 - val_loss: 13.4012 - val_accuracy: 0.8819 - val_precision: 0.1720 - val_recall: 0.4338 - val_f1_score: 0.2463\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1131 - accuracy: 0.9946 - precision: 0.1723 - recall: 0.4342 - f1_score: 0.2467 - val_loss: 17.6935 - val_accuracy: 0.8903 - val_precision: 0.1725 - val_recall: 0.4344 - val_f1_score: 0.2470\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0176 - accuracy: 0.9928 - precision: 0.1728 - recall: 0.4347 - f1_score: 0.2473 - val_loss: 18.0557 - val_accuracy: 0.8903 - val_precision: 0.1730 - val_recall: 0.4350 - val_f1_score: 0.2476\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0265 - accuracy: 0.9982 - precision: 0.1733 - recall: 0.4353 - f1_score: 0.2479 - val_loss: 16.9101 - val_accuracy: 0.8819 - val_precision: 0.1735 - val_recall: 0.4355 - val_f1_score: 0.2482\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0051 - accuracy: 0.9964 - precision: 0.1738 - recall: 0.4359 - f1_score: 0.2485 - val_loss: 16.1791 - val_accuracy: 0.8776 - val_precision: 0.1741 - val_recall: 0.4361 - val_f1_score: 0.2488\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0821 - accuracy: 0.9964 - precision: 0.1744 - recall: 0.4365 - f1_score: 0.2492 - val_loss: 15.7291 - val_accuracy: 0.8734 - val_precision: 0.1745 - val_recall: 0.4366 - val_f1_score: 0.2494\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.3291 - accuracy: 0.9946 - precision: 0.1748 - recall: 0.4369 - f1_score: 0.2497 - val_loss: 19.7535 - val_accuracy: 0.8819 - val_precision: 0.1750 - val_recall: 0.4371 - val_f1_score: 0.2500\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.7044 - accuracy: 0.9891 - precision: 0.1753 - recall: 0.4375 - f1_score: 0.2503 - val_loss: 23.0217 - val_accuracy: 0.8945 - val_precision: 0.1755 - val_recall: 0.4376 - val_f1_score: 0.2505\n",
      "Epoch 440/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 185ms/step - loss: 0.2336 - accuracy: 0.9819 - precision: 0.1758 - recall: 0.4380 - f1_score: 0.2509 - val_loss: 24.2942 - val_accuracy: 0.8734 - val_precision: 0.1760 - val_recall: 0.4380 - val_f1_score: 0.2511\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.4053 - accuracy: 0.9764 - precision: 0.1762 - recall: 0.4383 - f1_score: 0.2513 - val_loss: 18.3610 - val_accuracy: 0.8819 - val_precision: 0.1764 - val_recall: 0.4385 - val_f1_score: 0.2516\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.2663 - accuracy: 0.9783 - precision: 0.1767 - recall: 0.4387 - f1_score: 0.2519 - val_loss: 16.3387 - val_accuracy: 0.8819 - val_precision: 0.1768 - val_recall: 0.4388 - val_f1_score: 0.2521\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0731 - accuracy: 0.9909 - precision: 0.1771 - recall: 0.4392 - f1_score: 0.2524 - val_loss: 17.7455 - val_accuracy: 0.8776 - val_precision: 0.1773 - val_recall: 0.4393 - val_f1_score: 0.2527\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0389 - accuracy: 0.9909 - precision: 0.1776 - recall: 0.4396 - f1_score: 0.2530 - val_loss: 16.0862 - val_accuracy: 0.8819 - val_precision: 0.1778 - val_recall: 0.4399 - val_f1_score: 0.2533\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0916 - accuracy: 0.9909 - precision: 0.1781 - recall: 0.4402 - f1_score: 0.2535 - val_loss: 16.4436 - val_accuracy: 0.8861 - val_precision: 0.1783 - val_recall: 0.4404 - val_f1_score: 0.2539\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0424 - accuracy: 0.9964 - precision: 0.1786 - recall: 0.4408 - f1_score: 0.2542 - val_loss: 16.7052 - val_accuracy: 0.8903 - val_precision: 0.1788 - val_recall: 0.4409 - val_f1_score: 0.2545\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.3385 - accuracy: 0.9982 - precision: 0.1791 - recall: 0.4412 - f1_score: 0.2547 - val_loss: 15.2962 - val_accuracy: 0.8650 - val_precision: 0.1793 - val_recall: 0.4415 - val_f1_score: 0.2551\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0303 - accuracy: 0.9964 - precision: 0.1796 - recall: 0.4419 - f1_score: 0.2554 - val_loss: 12.1974 - val_accuracy: 0.8608 - val_precision: 0.1798 - val_recall: 0.4420 - val_f1_score: 0.2557\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0396 - accuracy: 0.9891 - precision: 0.1801 - recall: 0.4423 - f1_score: 0.2559 - val_loss: 12.4032 - val_accuracy: 0.8734 - val_precision: 0.1803 - val_recall: 0.4425 - val_f1_score: 0.2563\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.4108 - accuracy: 0.9909 - precision: 0.1806 - recall: 0.4429 - f1_score: 0.2566 - val_loss: 13.8000 - val_accuracy: 0.8650 - val_precision: 0.1808 - val_recall: 0.4431 - val_f1_score: 0.2568\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.2685 - accuracy: 0.9909 - precision: 0.1811 - recall: 0.4434 - f1_score: 0.2572 - val_loss: 18.4510 - val_accuracy: 0.8608 - val_precision: 0.1813 - val_recall: 0.4436 - val_f1_score: 0.2574\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1947 - accuracy: 0.9855 - precision: 0.1816 - recall: 0.4439 - f1_score: 0.2578 - val_loss: 13.3885 - val_accuracy: 0.8608 - val_precision: 0.1818 - val_recall: 0.4440 - val_f1_score: 0.2580\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0507 - accuracy: 0.9873 - precision: 0.1820 - recall: 0.4443 - f1_score: 0.2583 - val_loss: 13.5836 - val_accuracy: 0.8565 - val_precision: 0.1823 - val_recall: 0.4445 - val_f1_score: 0.2585\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1753 - accuracy: 0.9928 - precision: 0.1825 - recall: 0.4448 - f1_score: 0.2589 - val_loss: 15.5054 - val_accuracy: 0.8734 - val_precision: 0.1828 - val_recall: 0.4450 - val_f1_score: 0.2591\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0217 - accuracy: 0.9928 - precision: 0.1830 - recall: 0.4452 - f1_score: 0.2593 - val_loss: 13.6873 - val_accuracy: 0.8734 - val_precision: 0.1832 - val_recall: 0.4455 - val_f1_score: 0.2597\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0486 - accuracy: 0.9982 - precision: 0.1835 - recall: 0.4459 - f1_score: 0.2600 - val_loss: 14.2418 - val_accuracy: 0.8903 - val_precision: 0.1837 - val_recall: 0.4460 - val_f1_score: 0.2602\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0520 - accuracy: 0.9891 - precision: 0.1839 - recall: 0.4463 - f1_score: 0.2605 - val_loss: 12.4628 - val_accuracy: 0.8439 - val_precision: 0.1841 - val_recall: 0.4464 - val_f1_score: 0.2607\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0604 - accuracy: 0.9891 - precision: 0.1843 - recall: 0.4467 - f1_score: 0.2609 - val_loss: 12.8573 - val_accuracy: 0.8692 - val_precision: 0.1846 - val_recall: 0.4470 - val_f1_score: 0.2613\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.0069 - accuracy: 0.9982 - precision: 0.1849 - recall: 0.4474 - f1_score: 0.2617 - val_loss: 13.1177 - val_accuracy: 0.8776 - val_precision: 0.1851 - val_recall: 0.4475 - val_f1_score: 0.2619\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.1007 - accuracy: 0.9909 - precision: 0.1853 - recall: 0.4477 - f1_score: 0.2622 - val_loss: 14.0010 - val_accuracy: 0.8776 - val_precision: 0.1855 - val_recall: 0.4479 - val_f1_score: 0.2624\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.0394 - accuracy: 0.9946 - precision: 0.1858 - recall: 0.4482 - f1_score: 0.2627 - val_loss: 16.6846 - val_accuracy: 0.8819 - val_precision: 0.1860 - val_recall: 0.4484 - val_f1_score: 0.2629\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1142 - accuracy: 0.9909 - precision: 0.1863 - recall: 0.4488 - f1_score: 0.2633 - val_loss: 13.5058 - val_accuracy: 0.8776 - val_precision: 0.1864 - val_recall: 0.4489 - val_f1_score: 0.2634\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1408 - accuracy: 0.9891 - precision: 0.1866 - recall: 0.4492 - f1_score: 0.2637 - val_loss: 11.0844 - val_accuracy: 0.8819 - val_precision: 0.1868 - val_recall: 0.4493 - val_f1_score: 0.2639\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0625 - accuracy: 0.9946 - precision: 0.1871 - recall: 0.4497 - f1_score: 0.2643 - val_loss: 18.0058 - val_accuracy: 0.8439 - val_precision: 0.1873 - val_recall: 0.4499 - val_f1_score: 0.2645\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0732 - accuracy: 0.9909 - precision: 0.1876 - recall: 0.4502 - f1_score: 0.2648 - val_loss: 14.7047 - val_accuracy: 0.8776 - val_precision: 0.1878 - val_recall: 0.4503 - val_f1_score: 0.2650\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.1098 - accuracy: 0.9946 - precision: 0.1880 - recall: 0.4506 - f1_score: 0.2653 - val_loss: 16.5294 - val_accuracy: 0.8776 - val_precision: 0.1882 - val_recall: 0.4508 - val_f1_score: 0.2656\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0088 - accuracy: 0.9982 - precision: 0.1885 - recall: 0.4511 - f1_score: 0.2659 - val_loss: 18.4235 - val_accuracy: 0.8776 - val_precision: 0.1887 - val_recall: 0.4513 - val_f1_score: 0.2661\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.1092 - accuracy: 0.9909 - precision: 0.1890 - recall: 0.4516 - f1_score: 0.2665 - val_loss: 14.9573 - val_accuracy: 0.8692 - val_precision: 0.1892 - val_recall: 0.4517 - val_f1_score: 0.2667\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0752 - accuracy: 0.9909 - precision: 0.1894 - recall: 0.4520 - f1_score: 0.2670 - val_loss: 17.5210 - val_accuracy: 0.8692 - val_precision: 0.1897 - val_recall: 0.4522 - val_f1_score: 0.2672\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 186ms/step - loss: 8.8374e-05 - accuracy: 1.0000 - precision: 0.1899 - recall: 0.4525 - f1_score: 0.2675 - val_loss: 19.3723 - val_accuracy: 0.8945 - val_precision: 0.1901 - val_recall: 0.4526 - val_f1_score: 0.2678\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0223 - accuracy: 0.9982 - precision: 0.1904 - recall: 0.4530 - f1_score: 0.2681 - val_loss: 18.9578 - val_accuracy: 0.8945 - val_precision: 0.1906 - val_recall: 0.4531 - val_f1_score: 0.2684\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1578 - accuracy: 0.9909 - precision: 0.1908 - recall: 0.4533 - f1_score: 0.2686 - val_loss: 19.3010 - val_accuracy: 0.8819 - val_precision: 0.1911 - val_recall: 0.4536 - val_f1_score: 0.2689\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1190 - accuracy: 0.9909 - precision: 0.1914 - recall: 0.4539 - f1_score: 0.2692 - val_loss: 21.3197 - val_accuracy: 0.8903 - val_precision: 0.1916 - val_recall: 0.4541 - val_f1_score: 0.2695\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0338 - accuracy: 0.9982 - precision: 0.1918 - recall: 0.4543 - f1_score: 0.2697 - val_loss: 18.9415 - val_accuracy: 0.8819 - val_precision: 0.1920 - val_recall: 0.4545 - val_f1_score: 0.2700\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.0667 - accuracy: 0.9928 - precision: 0.1923 - recall: 0.4548 - f1_score: 0.2703 - val_loss: 16.5466 - val_accuracy: 0.8819 - val_precision: 0.1925 - val_recall: 0.4550 - val_f1_score: 0.2706\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.1644 - accuracy: 0.9946 - precision: 0.1928 - recall: 0.4553 - f1_score: 0.2709 - val_loss: 15.5027 - val_accuracy: 0.8819 - val_precision: 0.1930 - val_recall: 0.4554 - val_f1_score: 0.2711\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.0807 - accuracy: 0.9964 - precision: 0.1932 - recall: 0.4557 - f1_score: 0.2714 - val_loss: 15.5086 - val_accuracy: 0.8734 - val_precision: 0.1934 - val_recall: 0.4559 - val_f1_score: 0.2716\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1131 - accuracy: 0.9946 - precision: 0.1937 - recall: 0.4561 - f1_score: 0.2719 - val_loss: 19.8121 - val_accuracy: 0.8776 - val_precision: 0.1939 - val_recall: 0.4562 - val_f1_score: 0.2721\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0923 - accuracy: 0.9928 - precision: 0.1941 - recall: 0.4564 - f1_score: 0.2724 - val_loss: 16.9824 - val_accuracy: 0.8861 - val_precision: 0.1943 - val_recall: 0.4566 - val_f1_score: 0.2726\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0658 - accuracy: 0.9982 - precision: 0.1945 - recall: 0.4568 - f1_score: 0.2729 - val_loss: 17.1134 - val_accuracy: 0.8650 - val_precision: 0.1948 - val_recall: 0.4571 - val_f1_score: 0.2732\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0163 - accuracy: 1.0000 - precision: 0.1950 - recall: 0.4573 - f1_score: 0.2734 - val_loss: 19.4627 - val_accuracy: 0.8608 - val_precision: 0.1952 - val_recall: 0.4575 - val_f1_score: 0.2737\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0657 - accuracy: 0.9964 - precision: 0.1955 - recall: 0.4578 - f1_score: 0.2740 - val_loss: 21.3817 - val_accuracy: 0.8565 - val_precision: 0.1957 - val_recall: 0.4580 - val_f1_score: 0.2742\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3775 - accuracy: 0.9891 - precision: 0.1959 - recall: 0.4582 - f1_score: 0.2745 - val_loss: 21.0312 - val_accuracy: 0.7890 - val_precision: 0.1961 - val_recall: 0.4584 - val_f1_score: 0.2747\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2519 - accuracy: 0.9710 - precision: 0.1963 - recall: 0.4586 - f1_score: 0.2750 - val_loss: 21.6682 - val_accuracy: 0.8692 - val_precision: 0.1965 - val_recall: 0.4587 - val_f1_score: 0.2752\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1151 - accuracy: 0.9909 - precision: 0.1967 - recall: 0.4589 - f1_score: 0.2754 - val_loss: 28.2122 - val_accuracy: 0.8692 - val_precision: 0.1970 - val_recall: 0.4592 - val_f1_score: 0.2757\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1142 - accuracy: 0.9946 - precision: 0.1972 - recall: 0.4594 - f1_score: 0.2759 - val_loss: 29.0531 - val_accuracy: 0.8650 - val_precision: 0.1974 - val_recall: 0.4596 - val_f1_score: 0.2762\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2233 - accuracy: 0.9946 - precision: 0.1977 - recall: 0.4599 - f1_score: 0.2765 - val_loss: 25.5735 - val_accuracy: 0.8776 - val_precision: 0.1979 - val_recall: 0.4601 - val_f1_score: 0.2767\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0595 - accuracy: 0.9946 - precision: 0.1982 - recall: 0.4604 - f1_score: 0.2771 - val_loss: 23.2719 - val_accuracy: 0.8987 - val_precision: 0.1984 - val_recall: 0.4605 - val_f1_score: 0.2773\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0969 - accuracy: 0.9909 - precision: 0.1986 - recall: 0.4608 - f1_score: 0.2776 - val_loss: 28.5567 - val_accuracy: 0.8819 - val_precision: 0.1988 - val_recall: 0.4609 - val_f1_score: 0.2778\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3573 - accuracy: 0.9891 - precision: 0.1990 - recall: 0.4610 - f1_score: 0.2780 - val_loss: 29.0321 - val_accuracy: 0.8776 - val_precision: 0.1993 - val_recall: 0.4613 - val_f1_score: 0.2783\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2806 - accuracy: 0.9891 - precision: 0.1995 - recall: 0.4616 - f1_score: 0.2786 - val_loss: 29.6871 - val_accuracy: 0.8861 - val_precision: 0.1997 - val_recall: 0.4617 - val_f1_score: 0.2788\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0075 - accuracy: 0.9982 - precision: 0.2000 - recall: 0.4621 - f1_score: 0.2792 - val_loss: 27.1448 - val_accuracy: 0.8903 - val_precision: 0.2002 - val_recall: 0.4622 - val_f1_score: 0.2794\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.2720e-07 - accuracy: 1.0000 - precision: 0.2004 - recall: 0.4625 - f1_score: 0.2797 - val_loss: 26.7033 - val_accuracy: 0.8903 - val_precision: 0.2007 - val_recall: 0.4626 - val_f1_score: 0.2799\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.0578 - accuracy: 0.9946 - precision: 0.2009 - recall: 0.4629 - f1_score: 0.2802 - val_loss: 31.0721 - val_accuracy: 0.8861 - val_precision: 0.2011 - val_recall: 0.4631 - val_f1_score: 0.2804\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4226 - accuracy: 0.9873 - precision: 0.2014 - recall: 0.4634 - f1_score: 0.2808 - val_loss: 32.5838 - val_accuracy: 0.8819 - val_precision: 0.2016 - val_recall: 0.4635 - val_f1_score: 0.2810\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.0280 - accuracy: 0.9801 - precision: 0.2018 - recall: 0.4638 - f1_score: 0.2812 - val_loss: 33.7704 - val_accuracy: 0.8734 - val_precision: 0.2020 - val_recall: 0.4638 - val_f1_score: 0.2815\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3360 - accuracy: 0.9873 - precision: 0.2023 - recall: 0.4642 - f1_score: 0.2818 - val_loss: 21.0853 - val_accuracy: 0.8987 - val_precision: 0.2025 - val_recall: 0.4643 - val_f1_score: 0.2820\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3407 - accuracy: 0.9764 - precision: 0.2027 - recall: 0.4646 - f1_score: 0.2823 - val_loss: 25.2623 - val_accuracy: 0.8819 - val_precision: 0.2029 - val_recall: 0.4647 - val_f1_score: 0.2825\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.4790 - accuracy: 0.9837 - precision: 0.2031 - recall: 0.4649 - f1_score: 0.2827 - val_loss: 22.0514 - val_accuracy: 0.8734 - val_precision: 0.2033 - val_recall: 0.4650 - val_f1_score: 0.2829\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2343 - accuracy: 0.9873 - precision: 0.2036 - recall: 0.4653 - f1_score: 0.2833 - val_loss: 21.0287 - val_accuracy: 0.8692 - val_precision: 0.2038 - val_recall: 0.4654 - val_f1_score: 0.2834\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
    "history=model.fit(X_train, y_train, epochs=500, batch_size=32, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8bbbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 122ms/step - loss: 19.2258 - accuracy: 0.8593 - precision: 0.2038 - recall: 0.4652 - f1_score: 0.2834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[19.225784301757812,\n",
       " 0.8593155741691589,\n",
       " 0.20380493998527527,\n",
       " 0.4652235805988312,\n",
       " 0.28344032168388367]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66da15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c657c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'f1_score', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91a71cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'f1_score', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.title('Precision Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.xlabel('accuracy')\n",
    "\n",
    "plt.legend(['Precision', 'Recall','F1 Score'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a759ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d61389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04ec77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f578907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b33d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef84070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32352148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9e614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379ba1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610210b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e30654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26dc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab155cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
