{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bc20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b026630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 73, 73, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 73, 73, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 36, 36, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 17, 17, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 87,659,267\n",
      "Trainable params: 87,656,515\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#AlexNet Architecture for P estimation\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(300,300,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de4066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9305407",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lab_tested_data = pd.read_csv('C:\\\\Users\\\\Mahmood Yousaf\\\\Desktop\\\\FYP\\\\Final-Year-Project-Soil-Analysis-using-machine-learning\\\\Lab Results\\\\Soil_Lab_Results - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843f1705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1572\n"
     ]
    }
   ],
   "source": [
    "print(len(Lab_tested_data))\n",
    "#Getting sample id for each image with its lab value\n",
    "Sample_ID = Lab_tested_data.iloc[:,0]\n",
    "P_Value = Lab_tested_data.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd17e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    Labels = []\n",
    "    image_counter = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        x = filename.split(\"_\")\n",
    "        id = float(x[0])\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        width = 1000\n",
    "        height = 1000\n",
    "        dim = (width, height)\n",
    "        # resize image\n",
    "        img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        img = img[500:800,500:800] #Resizing the image\n",
    "        kernel = np.array([[-1,-1,-1], \n",
    "                   [-1, 9,-1],\n",
    "                   [-1,-1,-1]])\n",
    "        img = cv2.filter2D(img, -1, kernel) # applying the sharpening kernel.\n",
    "        Result = Sample_ID.isin([id])\n",
    "        Result = Sample_ID[Result];\n",
    "        if len(Result) >= 1:\n",
    "            print(image_counter)\n",
    "            image_counter = image_counter + 1\n",
    "            if len(Result) == 2:  \n",
    "                Result = Sample_ID[Sample_ID==Result.iloc[1]].index.tolist()\n",
    "                Id_1_index = Result[0]\n",
    "                Id_2_index = Result[1]\n",
    "                #Average of both inner and surface image soil result \n",
    "                P_lab_value = (P_Value[Id_2_index] + P_Value[Id_2_index]) / 2\n",
    "                #Assigning classs number 0,1,2,3 \n",
    "                if P_lab_value < 3.5:\n",
    "                    Labels.append([filename,img,0])\n",
    "                elif P_lab_value > 3.5 and P_lab_value < 7.0:\n",
    "                    Labels.append([filename,img,1])\n",
    "                elif P_lab_value > 7.0 and P_lab_value < 14.0:\n",
    "                    Labels.append([filename,img,2])\n",
    "                elif P_lab_value > 14.0:\n",
    "                    Labels.append([filename,img,3])\n",
    "            elif len(Result==1):\n",
    "                Result = Sample_ID[Sample_ID==Result.iloc[1]].index.tolist()\n",
    "                Id_1_index = Result[0]\n",
    "                P_lab_value = P_Value[Id_1_index]\n",
    "                #Assigning classs number 0,1,2,3 \n",
    "                if P_lab_value < 3.5:\n",
    "                    Labels.append([filename,img,0])\n",
    "                elif P_lab_value > 3.5 and P_lab_value < 7.0:\n",
    "                    Labels.append([filename,img,1])\n",
    "                elif P_lab_value > 7.0 and P_lab_value < 14.0:\n",
    "                    Labels.append([filename,img,2])\n",
    "                elif P_lab_value > 14.0:\n",
    "                    Labels.append([filename,img,3])\n",
    "        else:\n",
    "            print(len(Result))\n",
    "            print(\"Hi i am here for testing\")\n",
    "            continue\n",
    "    return Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea152f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n"
     ]
    }
   ],
   "source": [
    "#loading dataset \n",
    "dataset = load_images_from_folder('C:\\\\Users\\\\Mahmood Yousaf\\\\Desktop\\\\FYP\\\\Dataset RGB\\\\Training_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240d5e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1052\n"
     ]
    }
   ],
   "source": [
    "#Preparing data for model\n",
    "X = []\n",
    "Y = []\n",
    "for data in dataset:\n",
    "    X.append(data[1])\n",
    "    Y.append(data[2])\n",
    "print(Y)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90d0a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3)\n",
      "[0. 1. 0.]\n",
      "(1052, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "img_size = 300\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3)\n",
    "print(X[0].shape)\n",
    "Y = to_categorical(Y)\n",
    "print(Y[100])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e81e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1052, 300, 300, 3)\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y)\n",
    "print(Y[522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b3a9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmood Yousaf\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1348: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "18/18 [==============================] - ETA: 0s - loss: 60.3910 - accuracy: 0.7862 - precision: 0.0143 - recall: 0.0650 - f1_score: 0.0232        WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "18/18 [==============================] - 10s 315ms/step - loss: 60.3910 - accuracy: 0.7862 - precision: 0.0143 - recall: 0.0650 - f1_score: 0.0232 - val_loss: 1520.3812 - val_accuracy: 0.8270 - val_precision: 0.0426 - val_recall: 0.1758 - val_f1_score: 0.0683\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 10.3371 - accuracy: 0.7717 - precision: 0.0378 - recall: 0.1259 - f1_score: 0.0581 - val_loss: 190.2314 - val_accuracy: 0.8270 - val_precision: 0.0286 - val_recall: 0.1001 - val_f1_score: 0.0444\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 5.6480 - accuracy: 0.8098 - precision: 0.0407 - recall: 0.1777 - f1_score: 0.0662 - val_loss: 38.4538 - val_accuracy: 0.1857 - val_precision: 0.0405 - val_recall: 0.2469 - val_f1_score: 0.0695\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 2.3965 - accuracy: 0.7899 - precision: 0.0436 - recall: 0.3135 - f1_score: 0.0765 - val_loss: 21.6838 - val_accuracy: 0.8270 - val_precision: 0.0446 - val_recall: 0.2979 - val_f1_score: 0.0776\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 2.2463 - accuracy: 0.8297 - precision: 0.0468 - recall: 0.2872 - f1_score: 0.0805 - val_loss: 8.5426 - val_accuracy: 0.8270 - val_precision: 0.0475 - val_recall: 0.2747 - val_f1_score: 0.0810\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.5896 - accuracy: 0.8623 - precision: 0.0515 - recall: 0.2832 - f1_score: 0.0871 - val_loss: 2.4611 - val_accuracy: 0.8270 - val_precision: 0.0539 - val_recall: 0.2847 - val_f1_score: 0.0906\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0653 - accuracy: 0.8225 - precision: 0.0548 - recall: 0.2833 - f1_score: 0.0919 - val_loss: 1.8224 - val_accuracy: 0.8228 - val_precision: 0.0562 - val_recall: 0.2810 - val_f1_score: 0.0936\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.8230 - accuracy: 0.8678 - precision: 0.0582 - recall: 0.2828 - f1_score: 0.0965 - val_loss: 3.0856 - val_accuracy: 0.8228 - val_precision: 0.0601 - val_recall: 0.2829 - val_f1_score: 0.0992\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.5544 - accuracy: 0.8496 - precision: 0.0623 - recall: 0.2827 - f1_score: 0.1020 - val_loss: 1.4866 - val_accuracy: 0.8143 - val_precision: 0.0602 - val_recall: 0.2895 - val_f1_score: 0.0996\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.2525 - accuracy: 0.8279 - precision: 0.0620 - recall: 0.3080 - f1_score: 0.1032 - val_loss: 2.3092 - val_accuracy: 0.8270 - val_precision: 0.0625 - val_recall: 0.3006 - val_f1_score: 0.1036\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.3607 - accuracy: 0.8696 - precision: 0.0643 - recall: 0.3017 - f1_score: 0.1060 - val_loss: 1.9685 - val_accuracy: 0.8270 - val_precision: 0.0653 - val_recall: 0.2968 - val_f1_score: 0.1070\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0952 - accuracy: 0.8696 - precision: 0.0691 - recall: 0.3071 - f1_score: 0.1128 - val_loss: 1.9031 - val_accuracy: 0.8143 - val_precision: 0.0710 - val_recall: 0.3062 - val_f1_score: 0.1152\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0504 - accuracy: 0.8913 - precision: 0.0721 - recall: 0.3014 - f1_score: 0.1163 - val_loss: 1.4847 - val_accuracy: 0.7722 - val_precision: 0.0736 - val_recall: 0.2996 - val_f1_score: 0.1182\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1425 - accuracy: 0.8750 - precision: 0.0737 - recall: 0.2980 - f1_score: 0.1181 - val_loss: 2.8570 - val_accuracy: 0.8059 - val_precision: 0.0744 - val_recall: 0.2940 - val_f1_score: 0.1187\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6347 - accuracy: 0.8895 - precision: 0.0764 - recall: 0.3008 - f1_score: 0.1219 - val_loss: 2.2602 - val_accuracy: 0.8186 - val_precision: 0.0796 - val_recall: 0.3110 - val_f1_score: 0.1268\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.7619 - accuracy: 0.9022 - precision: 0.0809 - recall: 0.3122 - f1_score: 0.1285 - val_loss: 5.0293 - val_accuracy: 0.8228 - val_precision: 0.0818 - val_recall: 0.3107 - val_f1_score: 0.1296\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 1.0090 - accuracy: 0.8913 - precision: 0.0844 - recall: 0.3163 - f1_score: 0.1333 - val_loss: 2.7782 - val_accuracy: 0.8186 - val_precision: 0.0860 - val_recall: 0.3224 - val_f1_score: 0.1357\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1050 - accuracy: 0.9004 - precision: 0.0886 - recall: 0.3315 - f1_score: 0.1398 - val_loss: 3.7818 - val_accuracy: 0.8143 - val_precision: 0.0890 - val_recall: 0.3298 - val_f1_score: 0.1401\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.0539 - accuracy: 0.8551 - precision: 0.0895 - recall: 0.3335 - f1_score: 0.1412 - val_loss: 4.0314 - val_accuracy: 0.7384 - val_precision: 0.0878 - val_recall: 0.3425 - val_f1_score: 0.1397\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.2392 - accuracy: 0.8388 - precision: 0.0864 - recall: 0.3495 - f1_score: 0.1385 - val_loss: 4.8575 - val_accuracy: 0.8270 - val_precision: 0.0864 - val_recall: 0.3451 - val_f1_score: 0.1382\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1980 - accuracy: 0.8605 - precision: 0.0873 - recall: 0.3449 - f1_score: 0.1393 - val_loss: 5.9143 - val_accuracy: 0.8270 - val_precision: 0.0866 - val_recall: 0.3410 - val_f1_score: 0.1382\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1792 - accuracy: 0.8514 - precision: 0.0857 - recall: 0.3404 - f1_score: 0.1369 - val_loss: 2.4251 - val_accuracy: 0.8059 - val_precision: 0.0849 - val_recall: 0.3406 - val_f1_score: 0.1359\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0115 - accuracy: 0.8261 - precision: 0.0832 - recall: 0.3434 - f1_score: 0.1340 - val_loss: 4.5678 - val_accuracy: 0.7511 - val_precision: 0.0818 - val_recall: 0.3447 - val_f1_score: 0.1322\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.3032 - accuracy: 0.8750 - precision: 0.0811 - recall: 0.3451 - f1_score: 0.1313 - val_loss: 2.4774 - val_accuracy: 0.8143 - val_precision: 0.0815 - val_recall: 0.3445 - val_f1_score: 0.1318\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.7981 - accuracy: 0.8804 - precision: 0.0821 - recall: 0.3463 - f1_score: 0.1328 - val_loss: 8.2221 - val_accuracy: 0.8186 - val_precision: 0.0828 - val_recall: 0.3442 - val_f1_score: 0.1335\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.7946 - accuracy: 0.8986 - precision: 0.0840 - recall: 0.3438 - f1_score: 0.1350 - val_loss: 5.3149 - val_accuracy: 0.8312 - val_precision: 0.0842 - val_recall: 0.3409 - val_f1_score: 0.1350\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.2127 - accuracy: 0.8750 - precision: 0.0854 - recall: 0.3429 - f1_score: 0.1367 - val_loss: 5.1398 - val_accuracy: 0.7722 - val_precision: 0.0858 - val_recall: 0.3429 - val_f1_score: 0.1372\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1149 - accuracy: 0.8822 - precision: 0.0868 - recall: 0.3457 - f1_score: 0.1387 - val_loss: 2.5419 - val_accuracy: 0.8186 - val_precision: 0.0877 - val_recall: 0.3457 - val_f1_score: 0.1400\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6812 - accuracy: 0.8822 - precision: 0.0887 - recall: 0.3465 - f1_score: 0.1412 - val_loss: 2.6051 - val_accuracy: 0.8312 - val_precision: 0.0895 - val_recall: 0.3465 - val_f1_score: 0.1423\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.7180 - accuracy: 0.8877 - precision: 0.0914 - recall: 0.3488 - f1_score: 0.1448 - val_loss: 2.3356 - val_accuracy: 0.8270 - val_precision: 0.0920 - val_recall: 0.3473 - val_f1_score: 0.1455\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.7128 - accuracy: 0.8986 - precision: 0.0937 - recall: 0.3494 - f1_score: 0.1477 - val_loss: 2.2431 - val_accuracy: 0.8143 - val_precision: 0.0940 - val_recall: 0.3469 - val_f1_score: 0.1479\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.8782 - accuracy: 0.9130 - precision: 0.0950 - recall: 0.3476 - f1_score: 0.1493 - val_loss: 2.5078 - val_accuracy: 0.8059 - val_precision: 0.0960 - val_recall: 0.3485 - val_f1_score: 0.1505\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5589 - accuracy: 0.8967 - precision: 0.0966 - recall: 0.3485 - f1_score: 0.1512 - val_loss: 1.5814 - val_accuracy: 0.8017 - val_precision: 0.0973 - val_recall: 0.3483 - val_f1_score: 0.1522\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.7738 - accuracy: 0.9040 - precision: 0.0988 - recall: 0.3502 - f1_score: 0.1542 - val_loss: 2.2377 - val_accuracy: 0.6624 - val_precision: 0.0998 - val_recall: 0.3505 - val_f1_score: 0.1554\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.9963 - accuracy: 0.9058 - precision: 0.1013 - recall: 0.3545 - f1_score: 0.1576 - val_loss: 3.8804 - val_accuracy: 0.7848 - val_precision: 0.1019 - val_recall: 0.3538 - val_f1_score: 0.1583\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 2.0556 - accuracy: 0.8913 - precision: 0.1035 - recall: 0.3578 - f1_score: 0.1606 - val_loss: 4.1572 - val_accuracy: 0.7806 - val_precision: 0.1032 - val_recall: 0.3574 - val_f1_score: 0.1602\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.1886 - accuracy: 0.8696 - precision: 0.1045 - recall: 0.3606 - f1_score: 0.1620 - val_loss: 3.9370 - val_accuracy: 0.7806 - val_precision: 0.1050 - val_recall: 0.3608 - val_f1_score: 0.1626\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0762 - accuracy: 0.8949 - precision: 0.1057 - recall: 0.3614 - f1_score: 0.1636 - val_loss: 4.3616 - val_accuracy: 0.8101 - val_precision: 0.1061 - val_recall: 0.3613 - val_f1_score: 0.1640\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.3422 - accuracy: 0.8678 - precision: 0.1069 - recall: 0.3636 - f1_score: 0.1653 - val_loss: 2.0374 - val_accuracy: 0.7764 - val_precision: 0.1072 - val_recall: 0.3622 - val_f1_score: 0.1654\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.7693 - accuracy: 0.8877 - precision: 0.1072 - recall: 0.3619 - f1_score: 0.1655 - val_loss: 2.0928 - val_accuracy: 0.8101 - val_precision: 0.1064 - val_recall: 0.3615 - val_f1_score: 0.1645\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.6738 - accuracy: 0.8877 - precision: 0.1064 - recall: 0.3615 - f1_score: 0.1645 - val_loss: 2.5523 - val_accuracy: 0.8059 - val_precision: 0.1071 - val_recall: 0.3617 - val_f1_score: 0.1653\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.7320 - accuracy: 0.9130 - precision: 0.1087 - recall: 0.3657 - f1_score: 0.1676 - val_loss: 2.2323 - val_accuracy: 0.8270 - val_precision: 0.1095 - val_recall: 0.3669 - val_f1_score: 0.1686\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4422 - accuracy: 0.9040 - precision: 0.1104 - recall: 0.3692 - f1_score: 0.1699 - val_loss: 2.8909 - val_accuracy: 0.8186 - val_precision: 0.1111 - val_recall: 0.3690 - val_f1_score: 0.1708\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4363 - accuracy: 0.9221 - precision: 0.1125 - recall: 0.3710 - f1_score: 0.1726 - val_loss: 2.1753 - val_accuracy: 0.8354 - val_precision: 0.1141 - val_recall: 0.3736 - val_f1_score: 0.1748\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6486 - accuracy: 0.9438 - precision: 0.1149 - recall: 0.3757 - f1_score: 0.1760 - val_loss: 3.3189 - val_accuracy: 0.8354 - val_precision: 0.1166 - val_recall: 0.3773 - val_f1_score: 0.1782\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4239 - accuracy: 0.9293 - precision: 0.1180 - recall: 0.3792 - f1_score: 0.1799 - val_loss: 3.4951 - val_accuracy: 0.8354 - val_precision: 0.1190 - val_recall: 0.3796 - val_f1_score: 0.1812\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1015 - accuracy: 0.9094 - precision: 0.1201 - recall: 0.3809 - f1_score: 0.1826 - val_loss: 5.4535 - val_accuracy: 0.8270 - val_precision: 0.1211 - val_recall: 0.3826 - val_f1_score: 0.1840\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 1.0452 - accuracy: 0.9149 - precision: 0.1221 - recall: 0.3830 - f1_score: 0.1852 - val_loss: 2.9818 - val_accuracy: 0.8354 - val_precision: 0.1224 - val_recall: 0.3830 - val_f1_score: 0.1855\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.3655 - accuracy: 0.9149 - precision: 0.1229 - recall: 0.3854 - f1_score: 0.1864 - val_loss: 2.7263 - val_accuracy: 0.8186 - val_precision: 0.1230 - val_recall: 0.3859 - val_f1_score: 0.1866\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.3022 - accuracy: 0.9130 - precision: 0.1236 - recall: 0.3865 - f1_score: 0.1873 - val_loss: 2.9424 - val_accuracy: 0.8059 - val_precision: 0.1243 - val_recall: 0.3898 - val_f1_score: 0.1885\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2038 - accuracy: 0.9384 - precision: 0.1252 - recall: 0.3944 - f1_score: 0.1901 - val_loss: 3.2625 - val_accuracy: 0.8565 - val_precision: 0.1264 - val_recall: 0.3955 - val_f1_score: 0.1916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2225 - accuracy: 0.9420 - precision: 0.1278 - recall: 0.3974 - f1_score: 0.1934 - val_loss: 2.7643 - val_accuracy: 0.8439 - val_precision: 0.1288 - val_recall: 0.3985 - val_f1_score: 0.1946\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4513 - accuracy: 0.9475 - precision: 0.1300 - recall: 0.4009 - f1_score: 0.1963 - val_loss: 3.3274 - val_accuracy: 0.8270 - val_precision: 0.1313 - val_recall: 0.4022 - val_f1_score: 0.1979\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.4978 - accuracy: 0.9366 - precision: 0.1325 - recall: 0.4031 - f1_score: 0.1994 - val_loss: 6.2279 - val_accuracy: 0.7975 - val_precision: 0.1332 - val_recall: 0.4030 - val_f1_score: 0.2002\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.7059 - accuracy: 0.9203 - precision: 0.1345 - recall: 0.4056 - f1_score: 0.2020 - val_loss: 10.8577 - val_accuracy: 0.8186 - val_precision: 0.1350 - val_recall: 0.4051 - val_f1_score: 0.2025\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 2.1405 - accuracy: 0.8804 - precision: 0.1351 - recall: 0.4048 - f1_score: 0.2026 - val_loss: 12.4921 - val_accuracy: 0.7932 - val_precision: 0.1346 - val_recall: 0.4045 - val_f1_score: 0.2020\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 2.1329 - accuracy: 0.8424 - precision: 0.1343 - recall: 0.4035 - f1_score: 0.2015 - val_loss: 12.2865 - val_accuracy: 0.8059 - val_precision: 0.1342 - val_recall: 0.4019 - val_f1_score: 0.2012\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.2470 - accuracy: 0.8714 - precision: 0.1349 - recall: 0.4024 - f1_score: 0.2020 - val_loss: 9.2096 - val_accuracy: 0.8101 - val_precision: 0.1359 - val_recall: 0.4033 - val_f1_score: 0.2033\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.0946 - accuracy: 0.8986 - precision: 0.1366 - recall: 0.4039 - f1_score: 0.2042 - val_loss: 3.0572 - val_accuracy: 0.7932 - val_precision: 0.1371 - val_recall: 0.4034 - val_f1_score: 0.2047\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.3442 - accuracy: 0.8822 - precision: 0.1379 - recall: 0.4046 - f1_score: 0.2057 - val_loss: 4.3268 - val_accuracy: 0.7595 - val_precision: 0.1387 - val_recall: 0.4053 - val_f1_score: 0.2067\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.3957 - accuracy: 0.8786 - precision: 0.1391 - recall: 0.4055 - f1_score: 0.2071 - val_loss: 6.5896 - val_accuracy: 0.7848 - val_precision: 0.1398 - val_recall: 0.4065 - val_f1_score: 0.2081\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.5150 - accuracy: 0.9149 - precision: 0.1409 - recall: 0.4075 - f1_score: 0.2093 - val_loss: 4.5736 - val_accuracy: 0.8101 - val_precision: 0.1412 - val_recall: 0.4073 - val_f1_score: 0.2098\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.5811 - accuracy: 0.8931 - precision: 0.1420 - recall: 0.4084 - f1_score: 0.2107 - val_loss: 8.4680 - val_accuracy: 0.8143 - val_precision: 0.1423 - val_recall: 0.4087 - val_f1_score: 0.2111\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.0674 - accuracy: 0.8931 - precision: 0.1425 - recall: 0.4093 - f1_score: 0.2114 - val_loss: 16.1927 - val_accuracy: 0.8017 - val_precision: 0.1429 - val_recall: 0.4088 - val_f1_score: 0.2118\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.9582 - accuracy: 0.8967 - precision: 0.1427 - recall: 0.4086 - f1_score: 0.2115 - val_loss: 3.1234 - val_accuracy: 0.7679 - val_precision: 0.1429 - val_recall: 0.4077 - val_f1_score: 0.2116\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.9602 - accuracy: 0.8877 - precision: 0.1437 - recall: 0.4079 - f1_score: 0.2125 - val_loss: 7.7435 - val_accuracy: 0.7848 - val_precision: 0.1439 - val_recall: 0.4077 - val_f1_score: 0.2128\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.6381 - accuracy: 0.9112 - precision: 0.1442 - recall: 0.4082 - f1_score: 0.2131 - val_loss: 7.0870 - val_accuracy: 0.8228 - val_precision: 0.1451 - val_recall: 0.4088 - val_f1_score: 0.2142\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6051 - accuracy: 0.9239 - precision: 0.1455 - recall: 0.4098 - f1_score: 0.2147 - val_loss: 9.0686 - val_accuracy: 0.8101 - val_precision: 0.1463 - val_recall: 0.4110 - val_f1_score: 0.2158\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.7618 - accuracy: 0.9022 - precision: 0.1472 - recall: 0.4115 - f1_score: 0.2169 - val_loss: 5.7785 - val_accuracy: 0.8397 - val_precision: 0.1480 - val_recall: 0.4115 - val_f1_score: 0.2177\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.9901 - accuracy: 0.9293 - precision: 0.1489 - recall: 0.4126 - f1_score: 0.2188 - val_loss: 24.2503 - val_accuracy: 0.8186 - val_precision: 0.1497 - val_recall: 0.4141 - val_f1_score: 0.2199\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.5248 - accuracy: 0.9022 - precision: 0.1502 - recall: 0.4154 - f1_score: 0.2206 - val_loss: 10.7322 - val_accuracy: 0.8439 - val_precision: 0.1506 - val_recall: 0.4156 - val_f1_score: 0.2211\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4628 - accuracy: 0.9384 - precision: 0.1518 - recall: 0.4173 - f1_score: 0.2226 - val_loss: 6.4497 - val_accuracy: 0.8059 - val_precision: 0.1526 - val_recall: 0.4175 - val_f1_score: 0.2235\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6759 - accuracy: 0.9366 - precision: 0.1539 - recall: 0.4194 - f1_score: 0.2252 - val_loss: 4.8240 - val_accuracy: 0.8354 - val_precision: 0.1545 - val_recall: 0.4189 - val_f1_score: 0.2257\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.3429 - accuracy: 0.9493 - precision: 0.1555 - recall: 0.4199 - f1_score: 0.2270 - val_loss: 2.7755 - val_accuracy: 0.8186 - val_precision: 0.1564 - val_recall: 0.4202 - val_f1_score: 0.2280\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.4380 - accuracy: 0.9312 - precision: 0.1575 - recall: 0.4218 - f1_score: 0.2294 - val_loss: 6.3109 - val_accuracy: 0.8397 - val_precision: 0.1580 - val_recall: 0.4224 - val_f1_score: 0.2300\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.4627 - accuracy: 0.9402 - precision: 0.1590 - recall: 0.4240 - f1_score: 0.2313 - val_loss: 6.9389 - val_accuracy: 0.8312 - val_precision: 0.1597 - val_recall: 0.4250 - val_f1_score: 0.2322\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 1.1150 - accuracy: 0.9239 - precision: 0.1602 - recall: 0.4253 - f1_score: 0.2328 - val_loss: 7.3115 - val_accuracy: 0.8101 - val_precision: 0.1611 - val_recall: 0.4257 - val_f1_score: 0.2337\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.8333 - accuracy: 0.9239 - precision: 0.1621 - recall: 0.4264 - f1_score: 0.2349 - val_loss: 6.7329 - val_accuracy: 0.7848 - val_precision: 0.1625 - val_recall: 0.4266 - val_f1_score: 0.2354\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.0921 - accuracy: 0.9076 - precision: 0.1629 - recall: 0.4278 - f1_score: 0.2359 - val_loss: 10.5761 - val_accuracy: 0.8312 - val_precision: 0.1636 - val_recall: 0.4279 - val_f1_score: 0.2367\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.9922 - accuracy: 0.9366 - precision: 0.1644 - recall: 0.4280 - f1_score: 0.2376 - val_loss: 6.0148 - val_accuracy: 0.7975 - val_precision: 0.1652 - val_recall: 0.4276 - val_f1_score: 0.2383\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.7864 - accuracy: 0.9312 - precision: 0.1662 - recall: 0.4290 - f1_score: 0.2396 - val_loss: 13.3382 - val_accuracy: 0.8059 - val_precision: 0.1669 - val_recall: 0.4292 - val_f1_score: 0.2403\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 186ms/step - loss: 1.5598 - accuracy: 0.9058 - precision: 0.1676 - recall: 0.4292 - f1_score: 0.2411 - val_loss: 7.3717 - val_accuracy: 0.8059 - val_precision: 0.1678 - val_recall: 0.4288 - val_f1_score: 0.2413\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.6683 - accuracy: 0.9312 - precision: 0.1684 - recall: 0.4298 - f1_score: 0.2419 - val_loss: 8.5384 - val_accuracy: 0.8101 - val_precision: 0.1691 - val_recall: 0.4305 - val_f1_score: 0.2429\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.8886 - accuracy: 0.9257 - precision: 0.1698 - recall: 0.4317 - f1_score: 0.2438 - val_loss: 8.4450 - val_accuracy: 0.8354 - val_precision: 0.1704 - val_recall: 0.4320 - val_f1_score: 0.2444\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.1906 - accuracy: 0.9493 - precision: 0.1715 - recall: 0.4335 - f1_score: 0.2458 - val_loss: 8.9839 - val_accuracy: 0.8439 - val_precision: 0.1723 - val_recall: 0.4338 - val_f1_score: 0.2466\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.3006 - accuracy: 0.9402 - precision: 0.1728 - recall: 0.4354 - f1_score: 0.2474 - val_loss: 5.3065 - val_accuracy: 0.8143 - val_precision: 0.1731 - val_recall: 0.4364 - val_f1_score: 0.2479\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.7651 - accuracy: 0.9384 - precision: 0.1738 - recall: 0.4380 - f1_score: 0.2489 - val_loss: 5.8224 - val_accuracy: 0.8143 - val_precision: 0.1742 - val_recall: 0.4384 - val_f1_score: 0.2493\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.1502 - accuracy: 0.9312 - precision: 0.1748 - recall: 0.4395 - f1_score: 0.2501 - val_loss: 6.2058 - val_accuracy: 0.8397 - val_precision: 0.1754 - val_recall: 0.4400 - val_f1_score: 0.2508\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.5059 - accuracy: 0.9239 - precision: 0.1764 - recall: 0.4414 - f1_score: 0.2521 - val_loss: 8.6008 - val_accuracy: 0.8101 - val_precision: 0.1769 - val_recall: 0.4414 - val_f1_score: 0.2526\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.8264 - accuracy: 0.9149 - precision: 0.1777 - recall: 0.4421 - f1_score: 0.2536 - val_loss: 6.5549 - val_accuracy: 0.8354 - val_precision: 0.1782 - val_recall: 0.4419 - val_f1_score: 0.2540\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.5928 - accuracy: 0.9348 - precision: 0.1786 - recall: 0.4425 - f1_score: 0.2545 - val_loss: 6.7337 - val_accuracy: 0.8354 - val_precision: 0.1793 - val_recall: 0.4431 - val_f1_score: 0.2553\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.6334 - accuracy: 0.9312 - precision: 0.1796 - recall: 0.4436 - f1_score: 0.2557 - val_loss: 4.1079 - val_accuracy: 0.8186 - val_precision: 0.1803 - val_recall: 0.4435 - val_f1_score: 0.2563\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.8368 - accuracy: 0.9312 - precision: 0.1810 - recall: 0.4444 - f1_score: 0.2572 - val_loss: 6.9363 - val_accuracy: 0.8186 - val_precision: 0.1817 - val_recall: 0.4447 - val_f1_score: 0.2580\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.2775 - accuracy: 0.9130 - precision: 0.1823 - recall: 0.4451 - f1_score: 0.2587 - val_loss: 8.9865 - val_accuracy: 0.8397 - val_precision: 0.1829 - val_recall: 0.4451 - val_f1_score: 0.2592\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.4547 - accuracy: 0.8986 - precision: 0.1834 - recall: 0.4453 - f1_score: 0.2598 - val_loss: 7.2599 - val_accuracy: 0.8186 - val_precision: 0.1830 - val_recall: 0.4439 - val_f1_score: 0.2592\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.9183 - accuracy: 0.9130 - precision: 0.1835 - recall: 0.4436 - f1_score: 0.2596 - val_loss: 9.7091 - val_accuracy: 0.8270 - val_precision: 0.1840 - val_recall: 0.4432 - val_f1_score: 0.2601\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 3.3138 - accuracy: 0.9076 - precision: 0.1844 - recall: 0.4428 - f1_score: 0.2604 - val_loss: 4.4261 - val_accuracy: 0.8186 - val_precision: 0.1843 - val_recall: 0.4417 - val_f1_score: 0.2601\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.5823 - accuracy: 0.8949 - precision: 0.1847 - recall: 0.4417 - f1_score: 0.2605 - val_loss: 6.8956 - val_accuracy: 0.8354 - val_precision: 0.1852 - val_recall: 0.4409 - val_f1_score: 0.2609\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.2438 - accuracy: 0.9330 - precision: 0.1859 - recall: 0.4415 - f1_score: 0.2616 - val_loss: 4.9590 - val_accuracy: 0.8101 - val_precision: 0.1863 - val_recall: 0.4413 - val_f1_score: 0.2620\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.8662 - accuracy: 0.9384 - precision: 0.1872 - recall: 0.4425 - f1_score: 0.2631 - val_loss: 5.7189 - val_accuracy: 0.8397 - val_precision: 0.1877 - val_recall: 0.4425 - val_f1_score: 0.2636\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5051 - accuracy: 0.9475 - precision: 0.1885 - recall: 0.4430 - f1_score: 0.2645 - val_loss: 4.7596 - val_accuracy: 0.8101 - val_precision: 0.1894 - val_recall: 0.4432 - val_f1_score: 0.2654\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5816 - accuracy: 0.9457 - precision: 0.1901 - recall: 0.4436 - f1_score: 0.2661 - val_loss: 6.3214 - val_accuracy: 0.8354 - val_precision: 0.1908 - val_recall: 0.4438 - val_f1_score: 0.2668\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 1.2785 - accuracy: 0.9330 - precision: 0.1915 - recall: 0.4444 - f1_score: 0.2676 - val_loss: 5.2547 - val_accuracy: 0.7764 - val_precision: 0.1921 - val_recall: 0.4440 - val_f1_score: 0.2681\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0895 - accuracy: 0.9167 - precision: 0.1927 - recall: 0.4442 - f1_score: 0.2687 - val_loss: 5.0782 - val_accuracy: 0.8354 - val_precision: 0.1931 - val_recall: 0.4439 - val_f1_score: 0.2691\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.8626 - accuracy: 0.9420 - precision: 0.1939 - recall: 0.4447 - f1_score: 0.2701 - val_loss: 10.2259 - val_accuracy: 0.6203 - val_precision: 0.1947 - val_recall: 0.4451 - val_f1_score: 0.2709\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.0353 - accuracy: 0.9366 - precision: 0.1955 - recall: 0.4462 - f1_score: 0.2718 - val_loss: 15.1521 - val_accuracy: 0.8354 - val_precision: 0.1962 - val_recall: 0.4471 - val_f1_score: 0.2728\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.4401 - accuracy: 0.9438 - precision: 0.1972 - recall: 0.4483 - f1_score: 0.2739 - val_loss: 13.7301 - val_accuracy: 0.8312 - val_precision: 0.1980 - val_recall: 0.4488 - val_f1_score: 0.2748\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.4907 - accuracy: 0.9656 - precision: 0.1990 - recall: 0.4499 - f1_score: 0.2759 - val_loss: 8.9044 - val_accuracy: 0.8143 - val_precision: 0.1999 - val_recall: 0.4505 - val_f1_score: 0.2769\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.8145 - accuracy: 0.9656 - precision: 0.2007 - recall: 0.4508 - f1_score: 0.2777 - val_loss: 13.2205 - val_accuracy: 0.7511 - val_precision: 0.2011 - val_recall: 0.4509 - val_f1_score: 0.2781\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.4605 - accuracy: 0.9384 - precision: 0.2016 - recall: 0.4520 - f1_score: 0.2788 - val_loss: 15.8206 - val_accuracy: 0.7890 - val_precision: 0.2023 - val_recall: 0.4521 - val_f1_score: 0.2795\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.5459 - accuracy: 0.9348 - precision: 0.2031 - recall: 0.4528 - f1_score: 0.2804 - val_loss: 9.3054 - val_accuracy: 0.8270 - val_precision: 0.2033 - val_recall: 0.4520 - val_f1_score: 0.2804\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 179ms/step - loss: 1.0639 - accuracy: 0.9203 - precision: 0.2033 - recall: 0.4528 - f1_score: 0.2806 - val_loss: 4.6716 - val_accuracy: 0.7848 - val_precision: 0.2037 - val_recall: 0.4535 - val_f1_score: 0.2811\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 1.6210 - accuracy: 0.9221 - precision: 0.2039 - recall: 0.4541 - f1_score: 0.2814 - val_loss: 7.8567 - val_accuracy: 0.7764 - val_precision: 0.2038 - val_recall: 0.4539 - val_f1_score: 0.2812\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.8750 - accuracy: 0.9384 - precision: 0.2040 - recall: 0.4540 - f1_score: 0.2815 - val_loss: 8.0640 - val_accuracy: 0.8143 - val_precision: 0.2047 - val_recall: 0.4544 - val_f1_score: 0.2823\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.8073 - accuracy: 0.9384 - precision: 0.2054 - recall: 0.4553 - f1_score: 0.2831 - val_loss: 12.5745 - val_accuracy: 0.8354 - val_precision: 0.2056 - val_recall: 0.4553 - val_f1_score: 0.2833\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 1.8782 - accuracy: 0.9275 - precision: 0.2064 - recall: 0.4562 - f1_score: 0.2842 - val_loss: 7.7673 - val_accuracy: 0.8143 - val_precision: 0.2067 - val_recall: 0.4559 - val_f1_score: 0.2844\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 1.3400 - accuracy: 0.9257 - precision: 0.2071 - recall: 0.4568 - f1_score: 0.2850 - val_loss: 6.9232 - val_accuracy: 0.7764 - val_precision: 0.2077 - val_recall: 0.4570 - val_f1_score: 0.2856\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.8555 - accuracy: 0.9475 - precision: 0.2085 - recall: 0.4581 - f1_score: 0.2866 - val_loss: 20.2673 - val_accuracy: 0.5443 - val_precision: 0.2091 - val_recall: 0.4582 - val_f1_score: 0.2871\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.6794 - accuracy: 0.9475 - precision: 0.2095 - recall: 0.4585 - f1_score: 0.2876 - val_loss: 12.6691 - val_accuracy: 0.8270 - val_precision: 0.2102 - val_recall: 0.4587 - val_f1_score: 0.2883\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.5474 - accuracy: 0.9384 - precision: 0.2110 - recall: 0.4599 - f1_score: 0.2893 - val_loss: 22.9773 - val_accuracy: 0.8312 - val_precision: 0.2117 - val_recall: 0.4601 - val_f1_score: 0.2900\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.7728 - accuracy: 0.9601 - precision: 0.2125 - recall: 0.4609 - f1_score: 0.2909 - val_loss: 13.5948 - val_accuracy: 0.8481 - val_precision: 0.2131 - val_recall: 0.4612 - val_f1_score: 0.2915\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.4993 - accuracy: 0.9638 - precision: 0.2140 - recall: 0.4622 - f1_score: 0.2925 - val_loss: 9.6554 - val_accuracy: 0.7764 - val_precision: 0.2144 - val_recall: 0.4620 - val_f1_score: 0.2929\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.5289 - accuracy: 0.9583 - precision: 0.2151 - recall: 0.4628 - f1_score: 0.2937 - val_loss: 20.7154 - val_accuracy: 0.8397 - val_precision: 0.2157 - val_recall: 0.4634 - val_f1_score: 0.2944\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.6550 - accuracy: 0.9620 - precision: 0.2166 - recall: 0.4643 - f1_score: 0.2954 - val_loss: 30.8691 - val_accuracy: 0.8312 - val_precision: 0.2169 - val_recall: 0.4644 - val_f1_score: 0.2957\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.7629 - accuracy: 0.9565 - precision: 0.2177 - recall: 0.4653 - f1_score: 0.2966 - val_loss: 20.8440 - val_accuracy: 0.7975 - val_precision: 0.2182 - val_recall: 0.4654 - val_f1_score: 0.2971\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.2816 - accuracy: 0.9620 - precision: 0.2187 - recall: 0.4658 - f1_score: 0.2977 - val_loss: 15.8350 - val_accuracy: 0.8354 - val_precision: 0.2195 - val_recall: 0.4661 - val_f1_score: 0.2985\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.3245 - accuracy: 0.9493 - precision: 0.2202 - recall: 0.4667 - f1_score: 0.2992 - val_loss: 15.4137 - val_accuracy: 0.8270 - val_precision: 0.2209 - val_recall: 0.4671 - val_f1_score: 0.2999\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 1.1541 - accuracy: 0.9638 - precision: 0.2216 - recall: 0.4680 - f1_score: 0.3008 - val_loss: 14.5008 - val_accuracy: 0.8228 - val_precision: 0.2223 - val_recall: 0.4684 - val_f1_score: 0.3016\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 1.1432 - accuracy: 0.9547 - precision: 0.2230 - recall: 0.4689 - f1_score: 0.3022 - val_loss: 17.9637 - val_accuracy: 0.8354 - val_precision: 0.2236 - val_recall: 0.4691 - val_f1_score: 0.3029\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 1.2801 - accuracy: 0.9620 - precision: 0.2243 - recall: 0.4696 - f1_score: 0.3036 - val_loss: 17.1440 - val_accuracy: 0.8059 - val_precision: 0.2247 - val_recall: 0.4692 - val_f1_score: 0.3039\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.7752 - accuracy: 0.9583 - precision: 0.2252 - recall: 0.4699 - f1_score: 0.3045 - val_loss: 13.4517 - val_accuracy: 0.8270 - val_precision: 0.2258 - val_recall: 0.4701 - val_f1_score: 0.3051\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 1.7273 - accuracy: 0.9493 - precision: 0.2266 - recall: 0.4711 - f1_score: 0.3060 - val_loss: 27.3565 - val_accuracy: 0.8354 - val_precision: 0.2270 - val_recall: 0.4708 - val_f1_score: 0.3063\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.8811 - accuracy: 0.9565 - precision: 0.2278 - recall: 0.4714 - f1_score: 0.3072 - val_loss: 29.2327 - val_accuracy: 0.8354 - val_precision: 0.2285 - val_recall: 0.4717 - val_f1_score: 0.3079\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.4962 - accuracy: 0.9728 - precision: 0.2291 - recall: 0.4726 - f1_score: 0.3086 - val_loss: 66.3862 - val_accuracy: 0.8270 - val_precision: 0.2297 - val_recall: 0.4729 - val_f1_score: 0.3092\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.6374 - accuracy: 0.9674 - precision: 0.2304 - recall: 0.4734 - f1_score: 0.3099 - val_loss: 19.3474 - val_accuracy: 0.8017 - val_precision: 0.2307 - val_recall: 0.4735 - val_f1_score: 0.3103\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4434 - accuracy: 0.9529 - precision: 0.2309 - recall: 0.4741 - f1_score: 0.3105 - val_loss: 43.7419 - val_accuracy: 0.8312 - val_precision: 0.2316 - val_recall: 0.4744 - val_f1_score: 0.3112\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.6945 - accuracy: 0.9638 - precision: 0.2318 - recall: 0.4748 - f1_score: 0.3115 - val_loss: 29.6671 - val_accuracy: 0.8270 - val_precision: 0.2320 - val_recall: 0.4752 - val_f1_score: 0.3118\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.7724 - accuracy: 0.9764 - precision: 0.2328 - recall: 0.4761 - f1_score: 0.3127 - val_loss: 17.4292 - val_accuracy: 0.8228 - val_precision: 0.2333 - val_recall: 0.4761 - val_f1_score: 0.3131\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.9602 - accuracy: 0.9728 - precision: 0.2341 - recall: 0.4769 - f1_score: 0.3140 - val_loss: 16.9575 - val_accuracy: 0.7890 - val_precision: 0.2344 - val_recall: 0.4766 - val_f1_score: 0.3142\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.2296 - accuracy: 0.9493 - precision: 0.2347 - recall: 0.4769 - f1_score: 0.3146 - val_loss: 23.2478 - val_accuracy: 0.8312 - val_precision: 0.2354 - val_recall: 0.4769 - val_f1_score: 0.3152\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 3.4613 - accuracy: 0.9221 - precision: 0.2359 - recall: 0.4773 - f1_score: 0.3158 - val_loss: 69.8810 - val_accuracy: 0.8270 - val_precision: 0.2363 - val_recall: 0.4770 - val_f1_score: 0.3160\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 179ms/step - loss: 2.5497 - accuracy: 0.8822 - precision: 0.2351 - recall: 0.4768 - f1_score: 0.3149 - val_loss: 33.6262 - val_accuracy: 0.8312 - val_precision: 0.2352 - val_recall: 0.4770 - val_f1_score: 0.3151\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.0014 - accuracy: 0.9457 - precision: 0.2353 - recall: 0.4772 - f1_score: 0.3152 - val_loss: 14.7166 - val_accuracy: 0.8312 - val_precision: 0.2350 - val_recall: 0.4773 - val_f1_score: 0.3150\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 2.9248 - accuracy: 0.9348 - precision: 0.2354 - recall: 0.4779 - f1_score: 0.3154 - val_loss: 22.6989 - val_accuracy: 0.8270 - val_precision: 0.2353 - val_recall: 0.4778 - val_f1_score: 0.3153\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.8350 - accuracy: 0.9529 - precision: 0.2361 - recall: 0.4786 - f1_score: 0.3162 - val_loss: 15.1567 - val_accuracy: 0.8059 - val_precision: 0.2366 - val_recall: 0.4789 - val_f1_score: 0.3168\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.5487 - accuracy: 0.9493 - precision: 0.2367 - recall: 0.4797 - f1_score: 0.3170 - val_loss: 22.2000 - val_accuracy: 0.8312 - val_precision: 0.2368 - val_recall: 0.4797 - val_f1_score: 0.3171\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5971 - accuracy: 0.9710 - precision: 0.2373 - recall: 0.4804 - f1_score: 0.3177 - val_loss: 22.5645 - val_accuracy: 0.8354 - val_precision: 0.2379 - val_recall: 0.4807 - val_f1_score: 0.3183\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4072 - accuracy: 0.9674 - precision: 0.2387 - recall: 0.4813 - f1_score: 0.3191 - val_loss: 26.6550 - val_accuracy: 0.8354 - val_precision: 0.2393 - val_recall: 0.4814 - val_f1_score: 0.3197\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4232 - accuracy: 0.9783 - precision: 0.2399 - recall: 0.4820 - f1_score: 0.3204 - val_loss: 29.8915 - val_accuracy: 0.8354 - val_precision: 0.2405 - val_recall: 0.4822 - val_f1_score: 0.3209\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2048 - accuracy: 0.9783 - precision: 0.2410 - recall: 0.4829 - f1_score: 0.3215 - val_loss: 26.9745 - val_accuracy: 0.8312 - val_precision: 0.2415 - val_recall: 0.4832 - val_f1_score: 0.3220\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0746 - accuracy: 0.9837 - precision: 0.2421 - recall: 0.4837 - f1_score: 0.3227 - val_loss: 19.4618 - val_accuracy: 0.8143 - val_precision: 0.2424 - val_recall: 0.4839 - val_f1_score: 0.3230\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3716 - accuracy: 0.9819 - precision: 0.2425 - recall: 0.4843 - f1_score: 0.3232 - val_loss: 31.6702 - val_accuracy: 0.8228 - val_precision: 0.2430 - val_recall: 0.4844 - val_f1_score: 0.3236\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1870 - accuracy: 0.9475 - precision: 0.2429 - recall: 0.4850 - f1_score: 0.3237 - val_loss: 24.6122 - val_accuracy: 0.8354 - val_precision: 0.2426 - val_recall: 0.4851 - val_f1_score: 0.3234\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.2302 - accuracy: 0.9565 - precision: 0.2432 - recall: 0.4857 - f1_score: 0.3241 - val_loss: 27.0487 - val_accuracy: 0.8143 - val_precision: 0.2433 - val_recall: 0.4855 - val_f1_score: 0.3241\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1655 - accuracy: 0.9583 - precision: 0.2433 - recall: 0.4861 - f1_score: 0.3243 - val_loss: 27.5582 - val_accuracy: 0.8143 - val_precision: 0.2435 - val_recall: 0.4862 - val_f1_score: 0.3245\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.9330 - accuracy: 0.9638 - precision: 0.2438 - recall: 0.4866 - f1_score: 0.3249 - val_loss: 22.3244 - val_accuracy: 0.8186 - val_precision: 0.2443 - val_recall: 0.4867 - val_f1_score: 0.3253\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1112 - accuracy: 0.9601 - precision: 0.2450 - recall: 0.4873 - f1_score: 0.3261 - val_loss: 27.7250 - val_accuracy: 0.8143 - val_precision: 0.2454 - val_recall: 0.4874 - val_f1_score: 0.3264\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.3112 - accuracy: 0.9837 - precision: 0.2457 - recall: 0.4878 - f1_score: 0.3268 - val_loss: 29.0699 - val_accuracy: 0.8143 - val_precision: 0.2460 - val_recall: 0.4886 - val_f1_score: 0.3272\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.8236 - accuracy: 0.9746 - precision: 0.2465 - recall: 0.4894 - f1_score: 0.3279 - val_loss: 31.5875 - val_accuracy: 0.8312 - val_precision: 0.2469 - val_recall: 0.4894 - val_f1_score: 0.3282\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.6210 - accuracy: 0.9746 - precision: 0.2476 - recall: 0.4902 - f1_score: 0.3290 - val_loss: 21.3897 - val_accuracy: 0.8143 - val_precision: 0.2479 - val_recall: 0.4903 - val_f1_score: 0.3293\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2241 - accuracy: 0.9855 - precision: 0.2487 - recall: 0.4910 - f1_score: 0.3302 - val_loss: 23.2634 - val_accuracy: 0.8101 - val_precision: 0.2492 - val_recall: 0.4911 - val_f1_score: 0.3307\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4392 - accuracy: 0.9728 - precision: 0.2499 - recall: 0.4919 - f1_score: 0.3315 - val_loss: 18.3975 - val_accuracy: 0.8397 - val_precision: 0.2504 - val_recall: 0.4920 - val_f1_score: 0.3319\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4073 - accuracy: 0.9801 - precision: 0.2510 - recall: 0.4926 - f1_score: 0.3325 - val_loss: 21.0094 - val_accuracy: 0.8397 - val_precision: 0.2515 - val_recall: 0.4926 - val_f1_score: 0.3330\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5448 - accuracy: 0.9819 - precision: 0.2521 - recall: 0.4933 - f1_score: 0.3337 - val_loss: 24.5799 - val_accuracy: 0.8439 - val_precision: 0.2526 - val_recall: 0.4934 - val_f1_score: 0.3341\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5117 - accuracy: 0.9728 - precision: 0.2533 - recall: 0.4942 - f1_score: 0.3349 - val_loss: 22.6618 - val_accuracy: 0.8397 - val_precision: 0.2537 - val_recall: 0.4942 - val_f1_score: 0.3353\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1778 - accuracy: 0.9728 - precision: 0.2542 - recall: 0.4947 - f1_score: 0.3359 - val_loss: 20.5419 - val_accuracy: 0.8481 - val_precision: 0.2547 - val_recall: 0.4950 - val_f1_score: 0.3363\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0919 - accuracy: 0.9873 - precision: 0.2552 - recall: 0.4956 - f1_score: 0.3369 - val_loss: 21.2509 - val_accuracy: 0.8439 - val_precision: 0.2560 - val_recall: 0.4960 - val_f1_score: 0.3377\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0639 - accuracy: 0.9982 - precision: 0.2566 - recall: 0.4965 - f1_score: 0.3384 - val_loss: 20.4699 - val_accuracy: 0.8439 - val_precision: 0.2574 - val_recall: 0.4971 - val_f1_score: 0.3392\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0275 - accuracy: 0.9964 - precision: 0.2583 - recall: 0.4979 - f1_score: 0.3401 - val_loss: 17.0223 - val_accuracy: 0.8228 - val_precision: 0.2588 - val_recall: 0.4981 - val_f1_score: 0.3406\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1062 - accuracy: 0.9928 - precision: 0.2595 - recall: 0.4987 - f1_score: 0.3414 - val_loss: 19.0968 - val_accuracy: 0.8523 - val_precision: 0.2601 - val_recall: 0.4988 - val_f1_score: 0.3419\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.4542 - accuracy: 0.9764 - precision: 0.2606 - recall: 0.4994 - f1_score: 0.3425 - val_loss: 21.9536 - val_accuracy: 0.8270 - val_precision: 0.2609 - val_recall: 0.4998 - val_f1_score: 0.3429\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 179ms/step - loss: 1.8151 - accuracy: 0.9692 - precision: 0.2613 - recall: 0.5004 - f1_score: 0.3434 - val_loss: 21.4186 - val_accuracy: 0.8101 - val_precision: 0.2618 - val_recall: 0.5006 - val_f1_score: 0.3438\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.8028 - accuracy: 0.9801 - precision: 0.2624 - recall: 0.5008 - f1_score: 0.3444 - val_loss: 9.2474 - val_accuracy: 0.8143 - val_precision: 0.2629 - val_recall: 0.5007 - val_f1_score: 0.3448\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4517 - accuracy: 0.9638 - precision: 0.2631 - recall: 0.5011 - f1_score: 0.3450 - val_loss: 20.7787 - val_accuracy: 0.8439 - val_precision: 0.2633 - val_recall: 0.5011 - val_f1_score: 0.3452\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.5720 - accuracy: 0.9891 - precision: 0.2639 - recall: 0.5014 - f1_score: 0.3458 - val_loss: 21.7384 - val_accuracy: 0.8270 - val_precision: 0.2643 - val_recall: 0.5014 - val_f1_score: 0.3462\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.5054 - accuracy: 0.9891 - precision: 0.2647 - recall: 0.5019 - f1_score: 0.3466 - val_loss: 30.8415 - val_accuracy: 0.8354 - val_precision: 0.2654 - val_recall: 0.5021 - val_f1_score: 0.3472\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.4931 - accuracy: 0.9837 - precision: 0.2659 - recall: 0.5025 - f1_score: 0.3478 - val_loss: 26.5093 - val_accuracy: 0.8312 - val_precision: 0.2664 - val_recall: 0.5026 - val_f1_score: 0.3482\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.3558 - accuracy: 0.9837 - precision: 0.2672 - recall: 0.5033 - f1_score: 0.3491 - val_loss: 44.1834 - val_accuracy: 0.8312 - val_precision: 0.2677 - val_recall: 0.5033 - val_f1_score: 0.3495\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.5950 - accuracy: 0.9601 - precision: 0.2684 - recall: 0.5038 - f1_score: 0.3502 - val_loss: 19.9034 - val_accuracy: 0.8439 - val_precision: 0.2689 - val_recall: 0.5038 - val_f1_score: 0.3507\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4696 - accuracy: 0.9801 - precision: 0.2696 - recall: 0.5043 - f1_score: 0.3513 - val_loss: 68.4334 - val_accuracy: 0.8270 - val_precision: 0.2701 - val_recall: 0.5043 - val_f1_score: 0.3518\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 2.0472 - accuracy: 0.9728 - precision: 0.2707 - recall: 0.5048 - f1_score: 0.3524 - val_loss: 53.0502 - val_accuracy: 0.8270 - val_precision: 0.2713 - val_recall: 0.5050 - val_f1_score: 0.3530\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.7775 - accuracy: 0.9638 - precision: 0.2719 - recall: 0.5055 - f1_score: 0.3536 - val_loss: 52.8831 - val_accuracy: 0.8270 - val_precision: 0.2724 - val_recall: 0.5057 - val_f1_score: 0.3541\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 1.7287 - accuracy: 0.9674 - precision: 0.2728 - recall: 0.5058 - f1_score: 0.3544 - val_loss: 49.2074 - val_accuracy: 0.8228 - val_precision: 0.2734 - val_recall: 0.5062 - val_f1_score: 0.3551\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 2.0050 - accuracy: 0.9638 - precision: 0.2740 - recall: 0.5065 - f1_score: 0.3556 - val_loss: 45.3383 - val_accuracy: 0.7848 - val_precision: 0.2741 - val_recall: 0.5066 - val_f1_score: 0.3557\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 1.7810 - accuracy: 0.9620 - precision: 0.2744 - recall: 0.5072 - f1_score: 0.3562 - val_loss: 42.0576 - val_accuracy: 0.7679 - val_precision: 0.2744 - val_recall: 0.5074 - val_f1_score: 0.3562\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 3.5986 - accuracy: 0.9547 - precision: 0.2745 - recall: 0.5078 - f1_score: 0.3564 - val_loss: 28.4541 - val_accuracy: 0.8523 - val_precision: 0.2749 - val_recall: 0.5078 - val_f1_score: 0.3567\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.5977 - accuracy: 0.9511 - precision: 0.2752 - recall: 0.5081 - f1_score: 0.3571 - val_loss: 16.6708 - val_accuracy: 0.7890 - val_precision: 0.2746 - val_recall: 0.5081 - val_f1_score: 0.3565\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.5058 - accuracy: 0.9239 - precision: 0.2736 - recall: 0.5087 - f1_score: 0.3558 - val_loss: 31.5714 - val_accuracy: 0.8523 - val_precision: 0.2735 - val_recall: 0.5085 - val_f1_score: 0.3557\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 1.2728 - accuracy: 0.9384 - precision: 0.2736 - recall: 0.5087 - f1_score: 0.3558 - val_loss: 23.5535 - val_accuracy: 0.7848 - val_precision: 0.2729 - val_recall: 0.5090 - val_f1_score: 0.3553\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 1.2093 - accuracy: 0.9656 - precision: 0.2730 - recall: 0.5096 - f1_score: 0.3556 - val_loss: 27.3568 - val_accuracy: 0.7890 - val_precision: 0.2733 - val_recall: 0.5094 - val_f1_score: 0.3557\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.7302 - accuracy: 0.9764 - precision: 0.2737 - recall: 0.5098 - f1_score: 0.3562 - val_loss: 28.8037 - val_accuracy: 0.8312 - val_precision: 0.2743 - val_recall: 0.5100 - val_f1_score: 0.3567\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.8351 - accuracy: 0.9819 - precision: 0.2749 - recall: 0.5105 - f1_score: 0.3573 - val_loss: 27.3205 - val_accuracy: 0.8523 - val_precision: 0.2753 - val_recall: 0.5106 - val_f1_score: 0.3577\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.4691 - accuracy: 0.9891 - precision: 0.2758 - recall: 0.5110 - f1_score: 0.3583 - val_loss: 31.4712 - val_accuracy: 0.8439 - val_precision: 0.2764 - val_recall: 0.5110 - val_f1_score: 0.3587\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.0045 - accuracy: 0.9801 - precision: 0.2768 - recall: 0.5113 - f1_score: 0.3592 - val_loss: 35.4036 - val_accuracy: 0.8101 - val_precision: 0.2775 - val_recall: 0.5118 - val_f1_score: 0.3598\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2173 - accuracy: 0.9801 - precision: 0.2779 - recall: 0.5121 - f1_score: 0.3603 - val_loss: 32.7598 - val_accuracy: 0.8228 - val_precision: 0.2785 - val_recall: 0.5124 - val_f1_score: 0.3609\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.8196 - accuracy: 0.9764 - precision: 0.2790 - recall: 0.5129 - f1_score: 0.3614 - val_loss: 41.4839 - val_accuracy: 0.8397 - val_precision: 0.2795 - val_recall: 0.5130 - val_f1_score: 0.3619\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.0819 - accuracy: 0.9692 - precision: 0.2800 - recall: 0.5130 - f1_score: 0.3622 - val_loss: 30.2011 - val_accuracy: 0.8270 - val_precision: 0.2802 - val_recall: 0.5129 - val_f1_score: 0.3624\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0536 - accuracy: 0.9801 - precision: 0.2807 - recall: 0.5135 - f1_score: 0.3630 - val_loss: 41.8393 - val_accuracy: 0.8439 - val_precision: 0.2808 - val_recall: 0.5136 - val_f1_score: 0.3631\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 2.1606 - accuracy: 0.9547 - precision: 0.2811 - recall: 0.5141 - f1_score: 0.3634 - val_loss: 64.1082 - val_accuracy: 0.8312 - val_precision: 0.2812 - val_recall: 0.5144 - val_f1_score: 0.3636\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.5102 - accuracy: 0.9728 - precision: 0.2819 - recall: 0.5149 - f1_score: 0.3644 - val_loss: 49.4385 - val_accuracy: 0.8397 - val_precision: 0.2823 - val_recall: 0.5146 - val_f1_score: 0.3646\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
    "history=model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd8bbbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 46ms/step - loss: 43.6574 - accuracy: 0.8479 - precision: 0.2824 - recall: 0.5130 - f1_score: 0.3642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[43.65736389160156,\n",
       " 0.8479087352752686,\n",
       " 0.28237923979759216,\n",
       " 0.512971043586731,\n",
       " 0.3642479181289673]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66da15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c657c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a71cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'f1_score', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.title('Precision Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.xlabel('accuracy')\n",
    "\n",
    "plt.legend(['Precision', 'Recall','F1 Score'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a759ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained_model.history['loss'])\n",
    "plt.plot(trained_model.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss','val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d61389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04ec77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f578907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b33d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef84070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32352148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9e614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379ba1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610210b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e30654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26dc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab155cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
